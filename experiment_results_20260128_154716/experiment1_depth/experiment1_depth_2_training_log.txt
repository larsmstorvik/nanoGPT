Overriding config with config/train_tinystories.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-experiment1_depth-n_layer_2'
eval_interval = 250
eval_iters = 200
log_interval = 10

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False
wandb_project = 'tinystories'
wandb_run_name = 'experiment1_depth_n_layer_2'

dataset = 'tinystories'
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256

# baby GPT model :)
n_layer = 2
n_head = 8
n_embd = 256
dropout = 0.0

learning_rate = 0.001
max_iters = 5000
lr_decay_iters = 5000
min_lr = 0.0001
beta2 = 0.99

warmup_iters = 100

device = 'cuda:1'

tokens per iteration will be: 16,384
found vocab_size = 228 (inside data/tinystories/meta.pkl)
Initializing a new model from scratch
number of parameters: 1.63M
num decayed parameter tensors: 10, with 1,696,768 parameters
num non-decayed parameter tensors: 5, with 1,280 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 5.5408, val loss 5.5411
iter 0: loss 5.5431, time 1918.94ms, mfu -100.00%
iter 10: loss 4.3320, time 3.30ms, mfu 18.09%
iter 20: loss 3.7516, time 3.32ms, mfu 18.07%
iter 30: loss 3.0641, time 3.26ms, mfu 18.10%
iter 40: loss 2.6643, time 3.29ms, mfu 18.10%
iter 50: loss 2.4795, time 3.13ms, mfu 18.20%
iter 60: loss 2.3665, time 3.28ms, mfu 18.20%
iter 70: loss 2.3518, time 2.90ms, mfu 18.44%
iter 80: loss 2.3095, time 2.96ms, mfu 18.61%
iter 90: loss 2.2904, time 3.21ms, mfu 18.61%
iter 100: loss 2.2702, time 2.97ms, mfu 18.76%
iter 110: loss 2.2786, time 2.98ms, mfu 18.88%
iter 120: loss 2.2446, time 3.23ms, mfu 18.84%
iter 130: loss 2.1861, time 3.16ms, mfu 18.85%
iter 140: loss 2.1943, time 3.24ms, mfu 18.80%
iter 150: loss 2.1261, time 3.13ms, mfu 18.83%
iter 160: loss 2.1316, time 3.00ms, mfu 18.93%
iter 170: loss 2.0631, time 2.99ms, mfu 19.04%
iter 180: loss 2.0950, time 3.11ms, mfu 19.05%
iter 190: loss 2.1308, time 2.98ms, mfu 19.15%
iter 200: loss 1.9766, time 3.15ms, mfu 19.13%
iter 210: loss 1.9670, time 3.20ms, mfu 19.08%
iter 220: loss 1.9011, time 3.16ms, mfu 19.06%
iter 230: loss 1.8640, time 3.16ms, mfu 19.05%
iter 240: loss 1.8175, time 3.08ms, mfu 19.08%
step 250: train loss 1.8082, val loss 1.8062
saving checkpoint to out-experiment1_depth-n_layer_2
iter 250: loss 1.8321, time 1013.49ms, mfu 17.18%
iter 260: loss 1.8316, time 3.29ms, mfu 17.27%
iter 270: loss 1.7027, time 3.01ms, mfu 17.53%
iter 280: loss 1.6780, time 3.20ms, mfu 17.64%
iter 290: loss 1.6503, time 3.09ms, mfu 17.81%
iter 300: loss 1.6193, time 3.14ms, mfu 17.93%
iter 310: loss 1.5440, time 3.08ms, mfu 18.07%
iter 320: loss 1.5423, time 3.09ms, mfu 18.20%
iter 330: loss 1.5143, time 2.93ms, mfu 18.42%
iter 340: loss 1.4627, time 3.22ms, mfu 18.43%
iter 350: loss 1.4651, time 3.05ms, mfu 18.55%
iter 360: loss 1.4244, time 3.17ms, mfu 18.58%
iter 370: loss 1.4037, time 3.19ms, mfu 18.59%
iter 380: loss 1.4328, time 2.90ms, mfu 18.79%
iter 390: loss 1.3634, time 3.05ms, mfu 18.87%
iter 400: loss 1.2874, time 3.04ms, mfu 18.95%
iter 410: loss 1.3798, time 2.95ms, mfu 19.08%
iter 420: loss 1.2932, time 3.10ms, mfu 19.10%
iter 430: loss 1.2950, time 3.11ms, mfu 19.11%
iter 440: loss 1.2590, time 3.15ms, mfu 19.09%
iter 450: loss 1.2828, time 3.10ms, mfu 19.10%
iter 460: loss 1.2598, time 3.07ms, mfu 19.14%
iter 470: loss 1.2921, time 3.13ms, mfu 19.13%
iter 480: loss 1.2274, time 3.07ms, mfu 19.17%
iter 490: loss 1.2142, time 3.05ms, mfu 19.21%
step 500: train loss 1.2191, val loss 1.2228
saving checkpoint to out-experiment1_depth-n_layer_2
iter 500: loss 1.1905, time 1004.56ms, mfu 17.29%
iter 510: loss 1.2006, time 3.15ms, mfu 17.46%
iter 520: loss 1.1653, time 3.09ms, mfu 17.64%
iter 530: loss 1.2112, time 3.16ms, mfu 17.77%
iter 540: loss 1.1592, time 2.94ms, mfu 18.02%
iter 550: loss 1.1591, time 3.04ms, mfu 18.19%
iter 560: loss 1.1462, time 3.22ms, mfu 18.22%
iter 570: loss 1.1319, time 3.10ms, mfu 18.32%
iter 580: loss 1.1539, time 3.18ms, mfu 18.37%
iter 590: loss 1.1476, time 3.17ms, mfu 18.41%
iter 600: loss 1.1645, time 3.10ms, mfu 18.50%
iter 610: loss 1.0669, time 3.13ms, mfu 18.56%
iter 620: loss 1.1216, time 3.03ms, mfu 18.67%
iter 630: loss 1.1063, time 3.15ms, mfu 18.70%
iter 640: loss 1.0842, time 3.04ms, mfu 18.79%
iter 650: loss 1.1207, time 2.89ms, mfu 18.98%
iter 660: loss 1.0701, time 3.21ms, mfu 18.94%
iter 670: loss 1.1227, time 3.15ms, mfu 18.94%
iter 680: loss 1.0749, time 3.00ms, mfu 19.04%
iter 690: loss 1.0741, time 3.18ms, mfu 19.01%
iter 700: loss 1.0553, time 3.08ms, mfu 19.05%
iter 710: loss 1.0220, time 3.07ms, mfu 19.09%
iter 720: loss 1.0649, time 2.93ms, mfu 19.22%
iter 730: loss 1.0487, time 2.95ms, mfu 19.32%
iter 740: loss 1.0843, time 3.13ms, mfu 19.30%
step 750: train loss 1.0485, val loss 1.0497
saving checkpoint to out-experiment1_depth-n_layer_2
iter 750: loss 1.0492, time 1001.25ms, mfu 17.37%
iter 760: loss 1.0600, time 3.08ms, mfu 17.57%
iter 770: loss 1.0747, time 3.15ms, mfu 17.71%
iter 780: loss 1.0687, time 3.19ms, mfu 17.81%
iter 790: loss 1.0293, time 3.62ms, mfu 17.68%
iter 800: loss 1.0243, time 3.24ms, mfu 17.75%
iter 810: loss 1.0294, time 3.19ms, mfu 17.85%
iter 820: loss 0.9843, time 3.12ms, mfu 17.98%
iter 830: loss 1.0283, time 3.06ms, mfu 18.13%
iter 840: loss 0.9962, time 2.92ms, mfu 18.36%
iter 850: loss 1.0261, time 3.06ms, mfu 18.47%
iter 860: loss 1.0379, time 3.05ms, mfu 18.59%
iter 870: loss 0.9954, time 3.14ms, mfu 18.63%
iter 880: loss 0.9589, time 3.20ms, mfu 18.63%
iter 890: loss 0.9862, time 3.10ms, mfu 18.69%
iter 900: loss 0.9769, time 3.08ms, mfu 18.77%
iter 910: loss 1.0032, time 3.12ms, mfu 18.80%
iter 920: loss 0.9884, time 2.92ms, mfu 18.97%
iter 930: loss 0.9591, time 2.94ms, mfu 19.10%
iter 940: loss 0.9637, time 3.21ms, mfu 19.05%
iter 950: loss 0.9495, time 2.92ms, mfu 19.19%
iter 960: loss 0.9584, time 3.14ms, mfu 19.17%
iter 970: loss 0.9583, time 3.10ms, mfu 19.18%
iter 980: loss 0.9829, time 2.99ms, mfu 19.26%
iter 990: loss 0.9160, time 3.10ms, mfu 19.26%
step 1000: train loss 0.9536, val loss 0.9563
saving checkpoint to out-experiment1_depth-n_layer_2
iter 1000: loss 0.9920, time 1002.11ms, mfu 17.34%
iter 1010: loss 0.9866, time 3.11ms, mfu 17.53%
iter 1020: loss 0.9909, time 3.11ms, mfu 17.69%
iter 1030: loss 0.9486, time 3.11ms, mfu 17.84%
iter 1040: loss 0.9808, time 3.14ms, mfu 17.96%
iter 1050: loss 0.9544, time 2.87ms, mfu 18.24%
iter 1060: loss 0.9078, time 3.12ms, mfu 18.33%
iter 1070: loss 0.9901, time 3.15ms, mfu 18.39%
iter 1080: loss 0.9376, time 3.07ms, mfu 18.49%
iter 1090: loss 0.9720, time 3.15ms, mfu 18.54%
iter 1100: loss 0.9203, time 3.14ms, mfu 18.59%
iter 1110: loss 0.9187, time 3.09ms, mfu 18.66%
iter 1120: loss 0.8967, time 5.80ms, mfu 17.82%
iter 1130: loss 0.9228, time 3.25ms, mfu 17.88%
iter 1140: loss 0.9197, time 3.12ms, mfu 18.00%
iter 1150: loss 0.9377, time 3.20ms, mfu 18.07%
iter 1160: loss 0.9152, time 3.50ms, mfu 17.97%
iter 1170: loss 0.8892, time 3.15ms, mfu 18.07%
iter 1180: loss 0.9153, time 3.09ms, mfu 18.19%
iter 1190: loss 0.9046, time 3.26ms, mfu 18.20%
iter 1200: loss 0.9159, time 3.09ms, mfu 18.32%
iter 1210: loss 0.9197, time 3.06ms, mfu 18.44%
iter 1220: loss 0.9230, time 3.18ms, mfu 18.47%
iter 1230: loss 0.9020, time 2.92ms, mfu 18.67%
iter 1240: loss 0.9036, time 3.01ms, mfu 18.78%
step 1250: train loss 0.8927, val loss 0.8932
saving checkpoint to out-experiment1_depth-n_layer_2
iter 1250: loss 0.8937, time 989.93ms, mfu 16.91%
iter 1260: loss 0.8943, time 3.11ms, mfu 17.14%
iter 1270: loss 0.8897, time 3.09ms, mfu 17.36%
iter 1280: loss 0.8889, time 3.08ms, mfu 17.56%
iter 1290: loss 0.9005, time 3.12ms, mfu 17.72%
iter 1300: loss 0.9033, time 2.96ms, mfu 17.97%
iter 1310: loss 0.8759, time 2.88ms, mfu 18.24%
iter 1320: loss 0.9259, time 3.07ms, mfu 18.36%
iter 1330: loss 0.8939, time 3.06ms, mfu 18.48%
iter 1340: loss 0.8391, time 3.05ms, mfu 18.59%
iter 1350: loss 0.9101, time 3.08ms, mfu 18.67%
iter 1360: loss 0.8733, time 2.99ms, mfu 18.80%
iter 1370: loss 0.8935, time 3.03ms, mfu 18.89%
iter 1380: loss 0.9033, time 2.92ms, mfu 19.04%
iter 1390: loss 0.8580, time 2.96ms, mfu 19.15%
iter 1400: loss 0.8999, time 3.10ms, mfu 19.16%
iter 1410: loss 0.8854, time 3.08ms, mfu 19.18%
iter 1420: loss 0.9126, time 3.07ms, mfu 19.21%
iter 1430: loss 0.8696, time 3.07ms, mfu 19.24%
iter 1440: loss 0.8556, time 2.88ms, mfu 19.39%
iter 1450: loss 0.8573, time 3.04ms, mfu 19.41%
iter 1460: loss 0.8436, time 3.33ms, mfu 19.26%
iter 1470: loss 0.8981, time 3.13ms, mfu 19.24%
iter 1480: loss 0.9110, time 3.52ms, mfu 19.01%
iter 1490: loss 0.8709, time 4.94ms, mfu 18.32%
step 1500: train loss 0.8524, val loss 0.8520
saving checkpoint to out-experiment1_depth-n_layer_2
iter 1500: loss 0.8462, time 1000.58ms, mfu 16.49%
iter 1510: loss 0.8673, time 3.19ms, mfu 16.71%
iter 1520: loss 0.8460, time 3.10ms, mfu 16.97%
iter 1530: loss 0.8357, time 3.04ms, mfu 17.24%
iter 1540: loss 0.8584, time 3.06ms, mfu 17.47%
iter 1550: loss 0.8577, time 3.08ms, mfu 17.66%
iter 1560: loss 0.8516, time 3.12ms, mfu 17.80%
iter 1570: loss 0.8376, time 3.26ms, mfu 17.85%
iter 1580: loss 0.8385, time 2.91ms, mfu 18.12%
iter 1590: loss 0.8226, time 3.09ms, mfu 18.24%
iter 1600: loss 0.8539, time 3.08ms, mfu 18.36%
iter 1610: loss 0.8386, time 3.04ms, mfu 18.49%
iter 1620: loss 0.8275, time 3.04ms, mfu 18.60%
iter 1630: loss 0.8060, time 3.22ms, mfu 18.59%
iter 1640: loss 0.8309, time 3.19ms, mfu 18.61%
iter 1650: loss 0.8297, time 3.13ms, mfu 18.66%
iter 1660: loss 0.8353, time 2.93ms, mfu 18.83%
iter 1670: loss 0.8532, time 3.10ms, mfu 18.87%
iter 1680: loss 0.8142, time 3.04ms, mfu 18.95%
iter 1690: loss 0.8160, time 3.13ms, mfu 18.96%
iter 1700: loss 0.8154, time 3.03ms, mfu 19.04%
iter 1710: loss 0.8315, time 2.87ms, mfu 19.21%
iter 1720: loss 0.8621, time 3.10ms, mfu 19.22%
iter 1730: loss 0.8149, time 3.05ms, mfu 19.25%
iter 1740: loss 0.8212, time 3.08ms, mfu 19.26%
step 1750: train loss 0.8291, val loss 0.8242
saving checkpoint to out-experiment1_depth-n_layer_2
iter 1750: loss 0.8379, time 984.85ms, mfu 17.34%
iter 1760: loss 0.8102, time 3.12ms, mfu 17.52%
iter 1770: loss 0.8154, time 3.08ms, mfu 17.71%
iter 1780: loss 0.8389, time 2.89ms, mfu 18.01%
iter 1790: loss 0.8023, time 3.13ms, mfu 18.11%
iter 1800: loss 0.8088, time 3.08ms, mfu 18.24%
iter 1810: loss 0.7999, time 3.06ms, mfu 18.37%
iter 1820: loss 0.8435, time 3.02ms, mfu 18.51%
iter 1830: loss 0.8603, time 3.14ms, mfu 18.56%
iter 1840: loss 0.7850, time 3.07ms, mfu 18.64%
iter 1850: loss 0.8885, time 2.95ms, mfu 18.80%
iter 1860: loss 0.7797, time 3.10ms, mfu 18.85%
iter 1870: loss 0.7816, time 3.08ms, mfu 18.90%
iter 1880: loss 0.8129, time 2.90ms, mfu 19.07%
iter 1890: loss 0.8160, time 3.10ms, mfu 19.08%
iter 1900: loss 0.8063, time 3.21ms, mfu 19.04%
iter 1910: loss 0.7935, time 2.94ms, mfu 19.16%
iter 1920: loss 0.8555, time 3.08ms, mfu 19.19%
iter 1930: loss 0.8221, time 3.20ms, mfu 19.14%
iter 1940: loss 0.8029, time 2.99ms, mfu 19.22%
iter 1950: loss 0.8040, time 3.19ms, mfu 19.17%
iter 1960: loss 0.7721, time 3.25ms, mfu 19.09%
iter 1970: loss 0.8111, time 3.02ms, mfu 19.16%
iter 1980: loss 0.7845, time 3.17ms, mfu 19.13%
iter 1990: loss 0.7869, time 3.10ms, mfu 19.14%
step 2000: train loss 0.7986, val loss 0.8003
saving checkpoint to out-experiment1_depth-n_layer_2
iter 2000: loss 0.7720, time 988.96ms, mfu 17.23%
iter 2010: loss 0.8340, time 3.20ms, mfu 17.38%
iter 2020: loss 0.7900, time 3.01ms, mfu 17.62%
iter 2030: loss 0.8152, time 3.24ms, mfu 17.70%
iter 2040: loss 0.7620, time 3.20ms, mfu 17.80%
iter 2050: loss 0.7826, time 3.02ms, mfu 17.99%
iter 2060: loss 0.7896, time 3.16ms, mfu 18.09%
iter 2070: loss 0.7980, time 2.98ms, mfu 18.28%
iter 2080: loss 0.7962, time 2.98ms, mfu 18.45%
iter 2090: loss 0.7946, time 2.99ms, mfu 18.60%
iter 2100: loss 0.8077, time 3.15ms, mfu 18.64%
iter 2110: loss 0.7790, time 3.16ms, mfu 18.67%
iter 2120: loss 0.7985, time 3.27ms, mfu 18.63%
iter 2130: loss 0.8009, time 3.59ms, mfu 18.42%
iter 2140: loss 0.8201, time 3.26ms, mfu 18.41%
iter 2150: loss 0.7923, time 3.14ms, mfu 18.47%
iter 2160: loss 0.7828, time 3.10ms, mfu 18.55%
iter 2170: loss 0.7708, time 3.17ms, mfu 18.58%
iter 2180: loss 0.7799, time 3.14ms, mfu 18.63%
iter 2190: loss 0.7956, time 3.17ms, mfu 18.65%
iter 2200: loss 0.7724, time 3.06ms, mfu 18.73%
iter 2210: loss 0.7926, time 2.89ms, mfu 18.92%
iter 2220: loss 0.7795, time 3.28ms, mfu 18.85%
iter 2230: loss 0.7882, time 2.98ms, mfu 18.97%
iter 2240: loss 0.8071, time 3.10ms, mfu 19.00%
step 2250: train loss 0.7771, val loss 0.7805
saving checkpoint to out-experiment1_depth-n_layer_2
iter 2250: loss 0.8047, time 987.35ms, mfu 17.10%
iter 2260: loss 0.7919, time 2.92ms, mfu 17.44%
iter 2270: loss 0.8246, time 3.05ms, mfu 17.65%
iter 2280: loss 0.8096, time 3.05ms, mfu 17.84%
iter 2290: loss 0.7834, time 3.06ms, mfu 18.01%
iter 2300: loss 0.7773, time 3.02ms, mfu 18.18%
iter 2310: loss 0.7526, time 2.88ms, mfu 18.44%
iter 2320: loss 0.7837, time 3.12ms, mfu 18.50%
iter 2330: loss 0.7528, time 3.10ms, mfu 18.58%
iter 2340: loss 0.7476, time 2.98ms, mfu 18.73%
iter 2350: loss 0.7840, time 3.14ms, mfu 18.76%
iter 2360: loss 0.8003, time 2.86ms, mfu 18.97%
iter 2370: loss 0.7777, time 2.89ms, mfu 19.13%
iter 2380: loss 0.7614, time 2.92ms, mfu 19.27%
iter 2390: loss 0.7670, time 2.95ms, mfu 19.37%
iter 2400: loss 0.7574, time 3.06ms, mfu 19.38%
iter 2410: loss 0.7679, time 3.18ms, mfu 19.32%
iter 2420: loss 0.7511, time 3.06ms, mfu 19.34%
iter 2430: loss 0.7818, time 3.11ms, mfu 19.33%
iter 2440: loss 0.7477, time 3.11ms, mfu 19.31%
iter 2450: loss 0.7768, time 3.08ms, mfu 19.32%
iter 2460: loss 0.7649, time 3.04ms, mfu 19.35%
iter 2470: loss 0.7524, time 3.19ms, mfu 19.29%
iter 2480: loss 0.7645, time 3.14ms, mfu 19.26%
iter 2490: loss 0.7358, time 2.95ms, mfu 19.36%
step 2500: train loss 0.7626, val loss 0.7612
saving checkpoint to out-experiment1_depth-n_layer_2
iter 2500: loss 0.7457, time 989.89ms, mfu 17.43%
iter 2510: loss 0.7655, time 3.08ms, mfu 17.63%
iter 2520: loss 0.7532, time 3.42ms, mfu 17.61%
iter 2530: loss 0.7694, time 3.30ms, mfu 17.66%
iter 2540: loss 0.7172, time 3.16ms, mfu 17.78%
iter 2550: loss 0.7992, time 3.00ms, mfu 17.99%
iter 2560: loss 0.7643, time 3.20ms, mfu 18.05%
iter 2570: loss 0.7699, time 3.17ms, mfu 18.13%
iter 2580: loss 0.7605, time 3.07ms, mfu 18.26%
iter 2590: loss 0.7797, time 3.18ms, mfu 18.32%
iter 2600: loss 0.7505, time 3.10ms, mfu 18.41%
iter 2610: loss 0.7664, time 3.09ms, mfu 18.50%
iter 2620: loss 0.7948, time 3.05ms, mfu 18.61%
iter 2630: loss 0.7488, time 3.34ms, mfu 18.54%
iter 2640: loss 0.7618, time 3.23ms, mfu 18.53%
iter 2650: loss 0.7653, time 3.24ms, mfu 18.52%
iter 2660: loss 0.7593, time 3.01ms, mfu 18.65%
iter 2670: loss 0.7728, time 3.20ms, mfu 18.65%
iter 2680: loss 0.7637, time 3.06ms, mfu 18.74%
iter 2690: loss 0.7753, time 3.21ms, mfu 18.72%
iter 2700: loss 0.7547, time 3.19ms, mfu 18.72%
iter 2710: loss 0.7419, time 3.30ms, mfu 18.66%
iter 2720: loss 0.7325, time 3.24ms, mfu 18.64%
iter 2730: loss 0.7620, time 3.24ms, mfu 18.62%
iter 2740: loss 0.7586, time 3.19ms, mfu 18.63%
step 2750: train loss 0.7472, val loss 0.7494
saving checkpoint to out-experiment1_depth-n_layer_2
iter 2750: loss 0.7670, time 1005.25ms, mfu 16.77%
iter 2760: loss 0.7591, time 3.19ms, mfu 16.96%
iter 2770: loss 0.7254, time 3.08ms, mfu 17.21%
iter 2780: loss 0.7601, time 3.23ms, mfu 17.33%
iter 2790: loss 0.7373, time 3.10ms, mfu 17.52%
iter 2800: loss 0.7593, time 3.13ms, mfu 17.68%
iter 2810: loss 0.7283, time 2.98ms, mfu 17.91%
iter 2820: loss 0.7698, time 3.06ms, mfu 18.07%
iter 2830: loss 0.7145, time 3.10ms, mfu 18.19%
iter 2840: loss 0.7304, time 3.10ms, mfu 18.30%
iter 2850: loss 0.7468, time 3.84ms, mfu 18.02%
iter 2860: loss 0.7359, time 3.92ms, mfu 17.74%
iter 2870: loss 0.7306, time 4.54ms, mfu 17.28%
iter 2880: loss 0.7431, time 3.33ms, mfu 17.35%
iter 2890: loss 0.7435, time 3.08ms, mfu 17.55%
iter 2900: loss 0.7356, time 3.13ms, mfu 17.70%
iter 2910: loss 0.7426, time 3.01ms, mfu 17.91%
iter 2920: loss 0.6961, time 3.10ms, mfu 18.05%
iter 2930: loss 0.7486, time 3.16ms, mfu 18.13%
iter 2940: loss 0.7236, time 3.09ms, mfu 18.25%
iter 2950: loss 0.7707, time 2.94ms, mfu 18.46%
iter 2960: loss 0.7122, time 3.11ms, mfu 18.54%
iter 2970: loss 0.7347, time 2.90ms, mfu 18.74%
iter 2980: loss 0.7593, time 3.14ms, mfu 18.77%
iter 2990: loss 0.7779, time 2.91ms, mfu 18.94%
step 3000: train loss 0.7350, val loss 0.7369
saving checkpoint to out-experiment1_depth-n_layer_2
iter 3000: loss 0.7435, time 997.56ms, mfu 17.05%
iter 3010: loss 0.7421, time 3.28ms, mfu 17.17%
iter 3020: loss 0.7158, time 3.08ms, mfu 17.39%
iter 3030: loss 0.7409, time 2.99ms, mfu 17.65%
iter 3040: loss 0.7614, time 3.00ms, mfu 17.87%
iter 3050: loss 0.6998, time 2.94ms, mfu 18.12%
iter 3060: loss 0.7096, time 3.06ms, mfu 18.25%
iter 3070: loss 0.7330, time 3.07ms, mfu 18.37%
iter 3080: loss 0.6760, time 3.15ms, mfu 18.43%
iter 3090: loss 0.7133, time 3.16ms, mfu 18.48%
iter 3100: loss 0.7467, time 3.09ms, mfu 18.56%
iter 3110: loss 0.7468, time 3.11ms, mfu 18.62%
iter 3120: loss 0.7626, time 2.97ms, mfu 18.78%
iter 3130: loss 0.7265, time 2.89ms, mfu 18.96%
iter 3140: loss 0.6906, time 3.00ms, mfu 19.06%
iter 3150: loss 0.7095, time 3.12ms, mfu 19.06%
iter 3160: loss 0.7272, time 3.14ms, mfu 19.05%
iter 3170: loss 0.6875, time 3.06ms, mfu 19.10%
iter 3180: loss 0.7205, time 2.90ms, mfu 19.25%
iter 3190: loss 0.7382, time 3.29ms, mfu 19.14%
iter 3200: loss 0.7079, time 3.24ms, mfu 19.07%
iter 3210: loss 0.7284, time 3.20ms, mfu 19.03%
iter 3220: loss 0.7253, time 3.32ms, mfu 18.92%
iter 3230: loss 0.7080, time 3.17ms, mfu 18.92%
iter 3240: loss 0.7146, time 3.12ms, mfu 18.94%
step 3250: train loss 0.7228, val loss 0.7216
saving checkpoint to out-experiment1_depth-n_layer_2
iter 3250: loss 0.7330, time 997.81ms, mfu 17.05%
iter 3260: loss 0.7189, time 3.09ms, mfu 17.28%
iter 3270: loss 0.7333, time 2.95ms, mfu 17.58%
iter 3280: loss 0.7248, time 3.07ms, mfu 17.76%
iter 3290: loss 0.7321, time 3.04ms, mfu 17.95%
iter 3300: loss 0.7421, time 3.07ms, mfu 18.10%
iter 3310: loss 0.7111, time 3.14ms, mfu 18.19%
iter 3320: loss 0.7266, time 3.08ms, mfu 18.31%
iter 3330: loss 0.7491, time 3.12ms, mfu 18.39%
iter 3340: loss 0.7089, time 2.99ms, mfu 18.55%
iter 3350: loss 0.7119, time 3.09ms, mfu 18.63%
iter 3360: loss 0.7163, time 3.10ms, mfu 18.69%
iter 3370: loss 0.7406, time 3.09ms, mfu 18.76%
iter 3380: loss 0.7191, time 3.14ms, mfu 18.78%
iter 3390: loss 0.7042, time 3.13ms, mfu 18.81%
iter 3400: loss 0.7363, time 3.11ms, mfu 18.85%
iter 3410: loss 0.6694, time 3.19ms, mfu 18.84%
iter 3420: loss 0.6779, time 3.19ms, mfu 18.82%
iter 3430: loss 0.7567, time 2.95ms, mfu 18.97%
iter 3440: loss 0.7293, time 3.12ms, mfu 18.98%
iter 3450: loss 0.7373, time 3.13ms, mfu 18.99%
iter 3460: loss 0.7210, time 3.11ms, mfu 19.01%
iter 3470: loss 0.6987, time 3.20ms, mfu 18.98%
iter 3480: loss 0.7185, time 3.15ms, mfu 18.98%
iter 3490: loss 0.7411, time 3.10ms, mfu 19.00%
step 3500: train loss 0.7104, val loss 0.7128
saving checkpoint to out-experiment1_depth-n_layer_2
iter 3500: loss 0.6767, time 1004.58ms, mfu 17.11%
iter 3510: loss 0.7328, time 3.11ms, mfu 17.32%
iter 3520: loss 0.7093, time 3.26ms, mfu 17.42%
iter 3530: loss 0.7154, time 3.16ms, mfu 17.57%
iter 3540: loss 0.6944, time 3.20ms, mfu 17.68%
iter 3550: loss 0.6815, time 3.17ms, mfu 17.79%
iter 3560: loss 0.6938, time 3.13ms, mfu 17.92%
iter 3570: loss 0.7394, time 3.12ms, mfu 18.04%
iter 3580: loss 0.6755, time 3.18ms, mfu 18.11%
iter 3590: loss 0.7308, time 3.04ms, mfu 18.27%
iter 3600: loss 0.6827, time 3.13ms, mfu 18.35%
iter 3610: loss 0.6852, time 3.13ms, mfu 18.42%
iter 3620: loss 0.7281, time 3.09ms, mfu 18.52%
iter 3630: loss 0.6906, time 3.20ms, mfu 18.53%
iter 3640: loss 0.7267, time 3.10ms, mfu 18.60%
iter 3650: loss 0.7295, time 3.07ms, mfu 18.69%
iter 3660: loss 0.7226, time 3.15ms, mfu 18.72%
iter 3670: loss 0.7183, time 3.06ms, mfu 18.80%
iter 3680: loss 0.6854, time 3.06ms, mfu 18.87%
iter 3690: loss 0.7311, time 3.16ms, mfu 18.87%
iter 3700: loss 0.6969, time 3.19ms, mfu 18.85%
iter 3710: loss 0.6727, time 2.93ms, mfu 19.00%
iter 3720: loss 0.7194, time 3.17ms, mfu 18.99%
iter 3730: loss 0.6776, time 2.94ms, mfu 19.12%
iter 3740: loss 0.6753, time 3.08ms, mfu 19.14%
step 3750: train loss 0.7025, val loss 0.7037
saving checkpoint to out-experiment1_depth-n_layer_2
iter 3750: loss 0.7216, time 995.24ms, mfu 17.23%
iter 3760: loss 0.6928, time 3.03ms, mfu 17.48%
iter 3770: loss 0.6926, time 3.08ms, mfu 17.67%
iter 3780: loss 0.7446, time 3.07ms, mfu 17.85%
iter 3790: loss 0.7253, time 3.08ms, mfu 18.00%
iter 3800: loss 0.7135, time 3.03ms, mfu 18.17%
iter 3810: loss 0.7330, time 2.87ms, mfu 18.43%
iter 3820: loss 0.7136, time 3.07ms, mfu 18.54%
iter 3830: loss 0.7081, time 3.06ms, mfu 18.63%
iter 3840: loss 0.7127, time 3.15ms, mfu 18.66%
iter 3850: loss 0.7052, time 3.13ms, mfu 18.70%
iter 3860: loss 0.7157, time 3.03ms, mfu 18.80%
iter 3870: loss 0.6746, time 3.11ms, mfu 18.84%
iter 3880: loss 0.7119, time 2.95ms, mfu 18.98%
iter 3890: loss 0.6864, time 3.03ms, mfu 19.05%
iter 3900: loss 0.6921, time 3.10ms, mfu 19.08%
iter 3910: loss 0.6926, time 2.91ms, mfu 19.22%
iter 3920: loss 0.6972, time 3.11ms, mfu 19.22%
iter 3930: loss 0.7097, time 3.04ms, mfu 19.26%
iter 3940: loss 0.7084, time 2.92ms, mfu 19.38%
iter 3950: loss 0.6987, time 3.10ms, mfu 19.37%
iter 3960: loss 0.7171, time 3.10ms, mfu 19.35%
iter 3970: loss 0.6922, time 2.94ms, mfu 19.45%
iter 3980: loss 0.7455, time 2.93ms, mfu 19.54%
iter 3990: loss 0.6859, time 3.07ms, mfu 19.54%
step 4000: train loss 0.6975, val loss 0.6967
saving checkpoint to out-experiment1_depth-n_layer_2
iter 4000: loss 0.6839, time 974.41ms, mfu 17.59%
iter 4010: loss 0.6891, time 3.17ms, mfu 17.71%
iter 4020: loss 0.6589, time 3.10ms, mfu 17.86%
iter 4030: loss 0.6921, time 3.08ms, mfu 18.02%
iter 4040: loss 0.7292, time 3.09ms, mfu 18.15%
iter 4050: loss 0.6947, time 2.93ms, mfu 18.37%
iter 4060: loss 0.6779, time 3.13ms, mfu 18.44%
iter 4070: loss 0.7371, time 3.14ms, mfu 18.50%
iter 4080: loss 0.6898, time 3.11ms, mfu 18.57%
iter 4090: loss 0.6829, time 3.05ms, mfu 18.66%
iter 4100: loss 0.7189, time 3.06ms, mfu 18.75%
iter 4110: loss 0.6667, time 3.04ms, mfu 18.84%
iter 4120: loss 0.6802, time 2.90ms, mfu 19.01%
iter 4130: loss 0.6986, time 3.03ms, mfu 19.08%
iter 4140: loss 0.6978, time 3.01ms, mfu 19.16%
iter 4150: loss 0.6903, time 2.96ms, mfu 19.25%
iter 4160: loss 0.6959, time 3.18ms, mfu 19.21%
iter 4170: loss 0.6708, time 3.04ms, mfu 19.25%
iter 4180: loss 0.6719, time 3.02ms, mfu 19.31%
iter 4190: loss 0.6987, time 3.18ms, mfu 19.25%
iter 4200: loss 0.6704, time 3.08ms, mfu 19.27%
iter 4210: loss 0.7215, time 2.88ms, mfu 19.42%
iter 4220: loss 0.6937, time 3.04ms, mfu 19.44%
iter 4230: loss 0.6716, time 2.87ms, mfu 19.58%
iter 4240: loss 0.7079, time 3.14ms, mfu 19.52%
step 4250: train loss 0.6901, val loss 0.6907
saving checkpoint to out-experiment1_depth-n_layer_2
iter 4250: loss 0.7218, time 984.68ms, mfu 17.58%
iter 4260: loss 0.6719, time 3.20ms, mfu 17.68%
iter 4270: loss 0.6983, time 3.43ms, mfu 17.66%
iter 4280: loss 0.6833, time 3.36ms, mfu 17.67%
iter 4290: loss 0.6488, time 3.23ms, mfu 17.75%
iter 4300: loss 0.6829, time 3.13ms, mfu 17.89%
iter 4310: loss 0.6990, time 2.96ms, mfu 18.11%
iter 4320: loss 0.7067, time 3.13ms, mfu 18.21%
iter 4330: loss 0.6914, time 3.01ms, mfu 18.37%
iter 4340: loss 0.6839, time 3.05ms, mfu 18.49%
iter 4350: loss 0.7002, time 3.18ms, mfu 18.52%
iter 4360: loss 0.6681, time 2.98ms, mfu 18.67%
iter 4370: loss 0.6832, time 3.13ms, mfu 18.71%
iter 4380: loss 0.6752, time 2.91ms, mfu 18.89%
iter 4390: loss 0.7005, time 3.06ms, mfu 18.96%
iter 4400: loss 0.6899, time 3.15ms, mfu 18.95%
iter 4410: loss 0.7003, time 3.07ms, mfu 19.00%
iter 4420: loss 0.6996, time 3.08ms, mfu 19.04%
iter 4430: loss 0.6759, time 2.98ms, mfu 19.14%
iter 4440: loss 0.6469, time 2.92ms, mfu 19.27%
iter 4450: loss 0.7032, time 3.13ms, mfu 19.25%
iter 4460: loss 0.7234, time 2.89ms, mfu 19.39%
iter 4470: loss 0.6940, time 2.90ms, mfu 19.51%
iter 4480: loss 0.6489, time 3.13ms, mfu 19.46%
iter 4490: loss 0.6703, time 3.13ms, mfu 19.43%
step 4500: train loss 0.6836, val loss 0.6864
saving checkpoint to out-experiment1_depth-n_layer_2
iter 4500: loss 0.6933, time 976.86ms, mfu 17.49%
iter 4510: loss 0.6624, time 3.13ms, mfu 17.65%
iter 4520: loss 0.7118, time 3.11ms, mfu 17.80%
iter 4530: loss 0.6955, time 3.09ms, mfu 17.95%
iter 4540: loss 0.6852, time 3.06ms, mfu 18.11%
iter 4550: loss 0.7043, time 3.15ms, mfu 18.20%
iter 4560: loss 0.6668, time 3.19ms, mfu 18.25%
iter 4570: loss 0.6955, time 3.16ms, mfu 18.31%
iter 4580: loss 0.7057, time 2.89ms, mfu 18.54%
iter 4590: loss 0.6812, time 2.94ms, mfu 18.72%
iter 4600: loss 0.6781, time 3.27ms, mfu 18.67%
iter 4610: loss 0.6615, time 3.13ms, mfu 18.71%
iter 4620: loss 0.6468, time 3.20ms, mfu 18.71%
iter 4630: loss 0.6652, time 3.98ms, mfu 18.34%
iter 4640: loss 0.7286, time 3.11ms, mfu 18.42%
iter 4650: loss 0.6927, time 3.19ms, mfu 18.45%
iter 4660: loss 0.6860, time 3.11ms, mfu 18.52%
iter 4670: loss 0.6766, time 2.94ms, mfu 18.70%
iter 4680: loss 0.6593, time 3.23ms, mfu 18.68%
iter 4690: loss 0.6782, time 3.07ms, mfu 18.75%
iter 4700: loss 0.6684, time 3.09ms, mfu 18.81%
iter 4710: loss 0.6719, time 3.12ms, mfu 18.84%
iter 4720: loss 0.6739, time 3.12ms, mfu 18.87%
iter 4730: loss 0.6803, time 2.93ms, mfu 19.02%
iter 4740: loss 0.6976, time 3.58ms, mfu 18.78%
step 4750: train loss 0.6825, val loss 0.6804
saving checkpoint to out-experiment1_depth-n_layer_2
iter 4750: loss 0.6701, time 999.00ms, mfu 16.91%
iter 4760: loss 0.6508, time 3.33ms, mfu 17.01%
iter 4770: loss 0.6826, time 3.05ms, mfu 17.27%
iter 4780: loss 0.6834, time 3.10ms, mfu 17.47%
iter 4790: loss 0.6472, time 3.27ms, mfu 17.55%
iter 4800: loss 0.6577, time 3.12ms, mfu 17.70%
iter 4810: loss 0.7043, time 3.30ms, mfu 17.74%
iter 4820: loss 0.6676, time 3.09ms, mfu 17.90%
iter 4830: loss 0.6914, time 3.26ms, mfu 17.94%
iter 4840: loss 0.6444, time 3.17ms, mfu 18.03%
iter 4850: loss 0.6652, time 3.15ms, mfu 18.12%
iter 4860: loss 0.6825, time 3.11ms, mfu 18.23%
iter 4870: loss 0.6749, time 3.16ms, mfu 18.30%
iter 4880: loss 0.6979, time 3.12ms, mfu 18.38%
iter 4890: loss 0.6696, time 3.07ms, mfu 18.49%
iter 4900: loss 0.7190, time 3.07ms, mfu 18.58%
iter 4910: loss 0.6571, time 3.03ms, mfu 18.70%
iter 4920: loss 0.7081, time 2.93ms, mfu 18.86%
iter 4930: loss 0.6779, time 3.15ms, mfu 18.87%
iter 4940: loss 0.6472, time 3.09ms, mfu 18.91%
iter 4950: loss 0.6536, time 3.22ms, mfu 18.88%
iter 4960: loss 0.6507, time 5.20ms, mfu 18.14%
iter 4970: loss 0.6960, time 3.29ms, mfu 18.14%
iter 4980: loss 0.6773, time 3.08ms, mfu 18.26%
iter 4990: loss 0.6644, time 3.17ms, mfu 18.32%
step 5000: train loss 0.6776, val loss 0.6796
saving checkpoint to out-experiment1_depth-n_layer_2
iter 5000: loss 0.6944, time 1001.09ms, mfu 16.49%


STDERR:
/data/lst141/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
