Overriding config with config/train_tinystories.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-experiment2_width-n_embd_128'
eval_interval = 250
eval_iters = 200
log_interval = 10

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False
wandb_project = 'tinystories'
wandb_run_name = 'experiment2_width_n_embd_128'

dataset = 'tinystories'
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256

# baby GPT model :)
n_layer = 6
n_head = 8
n_embd = 128
dropout = 0.0

learning_rate = 0.001
max_iters = 5000
lr_decay_iters = 5000
min_lr = 0.0001
beta2 = 0.99

warmup_iters = 100

device = 'cuda:1'

tokens per iteration will be: 16,384
found vocab_size = 228 (inside data/tinystories/meta.pkl)
Initializing a new model from scratch
number of parameters: 1.21M
num decayed parameter tensors: 26, with 1,241,600 parameters
num non-decayed parameter tensors: 13, with 1,664 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 5.4497, val loss 5.4493
iter 0: loss 5.4482, time 11242.71ms, mfu -100.00%
iter 10: loss 4.7515, time 4.31ms, mfu 11.72%
iter 20: loss 4.4314, time 4.42ms, mfu 11.69%
iter 30: loss 3.9461, time 4.34ms, mfu 11.69%
iter 40: loss 3.4777, time 4.52ms, mfu 11.64%
iter 50: loss 3.0457, time 4.42ms, mfu 11.62%
iter 60: loss 2.7428, time 4.62ms, mfu 11.55%
iter 70: loss 2.6056, time 4.56ms, mfu 11.50%
iter 80: loss 2.4712, time 4.39ms, mfu 11.50%
iter 90: loss 2.4142, time 4.46ms, mfu 11.48%
iter 100: loss 2.3622, time 4.40ms, mfu 11.48%
iter 110: loss 2.3733, time 4.47ms, mfu 11.47%
iter 120: loss 2.3297, time 4.48ms, mfu 11.45%
iter 130: loss 2.3093, time 4.49ms, mfu 11.43%
iter 140: loss 2.2943, time 4.46ms, mfu 11.42%
iter 150: loss 2.2812, time 4.45ms, mfu 11.41%
iter 160: loss 2.2623, time 4.57ms, mfu 11.37%
iter 170: loss 2.2117, time 4.62ms, mfu 11.33%
iter 180: loss 2.1991, time 4.54ms, mfu 11.31%
iter 190: loss 2.1795, time 4.48ms, mfu 11.31%
iter 200: loss 2.1372, time 4.26ms, mfu 11.36%
iter 210: loss 2.1213, time 4.29ms, mfu 11.40%
iter 220: loss 2.1283, time 4.57ms, mfu 11.37%
iter 230: loss 2.0867, time 4.46ms, mfu 11.37%
iter 240: loss 2.0753, time 4.46ms, mfu 11.36%
step 250: train loss 2.0566, val loss 2.0571
saving checkpoint to out-experiment2_width-n_embd_128
iter 250: loss 2.0537, time 969.06ms, mfu 10.23%
iter 260: loss 2.0118, time 4.56ms, mfu 10.32%
iter 270: loss 1.9998, time 4.66ms, mfu 10.37%
iter 280: loss 1.9571, time 4.53ms, mfu 10.45%
iter 290: loss 1.9295, time 4.59ms, mfu 10.50%
iter 300: loss 1.9074, time 4.56ms, mfu 10.56%
iter 310: loss 1.8680, time 4.43ms, mfu 10.65%
iter 320: loss 1.8488, time 4.25ms, mfu 10.77%
iter 330: loss 1.8521, time 4.21ms, mfu 10.89%
iter 340: loss 1.7450, time 4.55ms, mfu 10.91%
iter 350: loss 1.7537, time 4.43ms, mfu 10.96%
iter 360: loss 1.7162, time 4.62ms, mfu 10.96%
iter 370: loss 1.6950, time 4.36ms, mfu 11.02%
iter 380: loss 1.6650, time 4.57ms, mfu 11.03%
iter 390: loss 1.6504, time 4.59ms, mfu 11.03%
iter 400: loss 1.6406, time 4.53ms, mfu 11.04%
iter 410: loss 1.6023, time 4.54ms, mfu 11.05%
iter 420: loss 1.5916, time 4.22ms, mfu 11.14%
iter 430: loss 1.4982, time 4.20ms, mfu 11.23%
iter 440: loss 1.5327, time 4.20ms, mfu 11.31%
iter 450: loss 1.5094, time 4.67ms, mfu 11.26%
iter 460: loss 1.4903, time 4.43ms, mfu 11.27%
iter 470: loss 1.4321, time 4.53ms, mfu 11.26%
iter 480: loss 1.4337, time 4.52ms, mfu 11.25%
iter 490: loss 1.4631, time 4.55ms, mfu 11.24%
step 500: train loss 1.4119, val loss 1.4099
saving checkpoint to out-experiment2_width-n_embd_128
iter 500: loss 1.4392, time 1056.47ms, mfu 10.12%
iter 510: loss 1.4392, time 4.70ms, mfu 10.19%
iter 520: loss 1.3521, time 4.27ms, mfu 10.35%
iter 530: loss 1.3423, time 4.32ms, mfu 10.49%
iter 540: loss 1.3934, time 4.46ms, mfu 10.57%
iter 550: loss 1.3468, time 4.57ms, mfu 10.62%
iter 560: loss 1.3413, time 4.32ms, mfu 10.73%
iter 570: loss 1.3228, time 4.46ms, mfu 10.79%
iter 580: loss 1.3441, time 4.24ms, mfu 10.90%
iter 590: loss 1.2933, time 4.62ms, mfu 10.90%
iter 600: loss 1.3078, time 4.43ms, mfu 10.95%
iter 610: loss 1.2747, time 4.54ms, mfu 10.97%
iter 620: loss 1.2863, time 4.57ms, mfu 10.98%
iter 630: loss 1.2625, time 4.64ms, mfu 10.97%
iter 640: loss 1.2461, time 4.65ms, mfu 10.96%
iter 650: loss 1.2373, time 4.66ms, mfu 10.95%
iter 660: loss 1.2059, time 4.76ms, mfu 10.91%
iter 670: loss 1.1929, time 4.33ms, mfu 10.99%
iter 680: loss 1.2170, time 4.45ms, mfu 11.02%
iter 690: loss 1.2269, time 4.21ms, mfu 11.12%
iter 700: loss 1.1795, time 4.45ms, mfu 11.14%
iter 710: loss 1.1765, time 4.51ms, mfu 11.15%
iter 720: loss 1.1723, time 4.59ms, mfu 11.14%
iter 730: loss 1.1843, time 4.42ms, mfu 11.17%
iter 740: loss 1.1678, time 4.40ms, mfu 11.20%
step 750: train loss 1.1622, val loss 1.1679
saving checkpoint to out-experiment2_width-n_embd_128
iter 750: loss 1.1908, time 1021.74ms, mfu 10.08%
iter 760: loss 1.1541, time 4.56ms, mfu 10.18%
iter 770: loss 1.2102, time 4.44ms, mfu 10.30%
iter 780: loss 1.1388, time 4.45ms, mfu 10.41%
iter 790: loss 1.1296, time 4.62ms, mfu 10.46%
iter 800: loss 1.1808, time 4.22ms, mfu 10.61%
iter 810: loss 1.1329, time 4.53ms, mfu 10.67%
iter 820: loss 1.1309, time 4.47ms, mfu 10.73%
iter 830: loss 1.1235, time 4.48ms, mfu 10.79%
iter 840: loss 1.1198, time 4.48ms, mfu 10.84%
iter 850: loss 1.0945, time 4.53ms, mfu 10.87%
iter 860: loss 1.1239, time 4.69ms, mfu 10.86%
iter 870: loss 1.1057, time 4.48ms, mfu 10.90%
iter 880: loss 1.0778, time 4.55ms, mfu 10.92%
iter 890: loss 1.0624, time 4.34ms, mfu 10.99%
iter 900: loss 1.0486, time 4.17ms, mfu 11.10%
iter 910: loss 1.0990, time 4.16ms, mfu 11.21%
iter 920: loss 1.0734, time 4.52ms, mfu 11.21%
iter 930: loss 1.0643, time 4.41ms, mfu 11.23%
iter 940: loss 1.0785, time 4.42ms, mfu 11.25%
iter 950: loss 1.0339, time 4.19ms, mfu 11.33%
iter 960: loss 1.0824, time 4.40ms, mfu 11.35%
iter 970: loss 1.0309, time 4.56ms, mfu 11.32%
iter 980: loss 1.0481, time 4.50ms, mfu 11.31%
iter 990: loss 1.0516, time 4.50ms, mfu 11.30%
step 1000: train loss 1.0387, val loss 1.0384
saving checkpoint to out-experiment2_width-n_embd_128
iter 1000: loss 1.0596, time 1033.93ms, mfu 10.18%
iter 1010: loss 1.0346, time 4.63ms, mfu 10.25%
iter 1020: loss 1.0188, time 4.52ms, mfu 10.34%
iter 1030: loss 1.0696, time 4.50ms, mfu 10.43%
iter 1040: loss 1.0098, time 4.39ms, mfu 10.54%
iter 1050: loss 1.0292, time 4.35ms, mfu 10.65%
iter 1060: loss 1.0179, time 4.59ms, mfu 10.68%
iter 1070: loss 1.0108, time 4.33ms, mfu 10.78%
iter 1080: loss 1.0043, time 4.40ms, mfu 10.85%
iter 1090: loss 1.0001, time 4.49ms, mfu 10.89%
iter 1100: loss 0.9886, time 4.27ms, mfu 10.99%
iter 1110: loss 1.0157, time 4.49ms, mfu 11.01%
iter 1120: loss 1.0104, time 4.61ms, mfu 11.01%
iter 1130: loss 1.0074, time 4.48ms, mfu 11.03%
iter 1140: loss 0.9943, time 4.51ms, mfu 11.05%
iter 1150: loss 0.9968, time 4.38ms, mfu 11.10%
iter 1160: loss 0.9912, time 4.28ms, mfu 11.17%
iter 1170: loss 1.0279, time 4.56ms, mfu 11.16%
iter 1180: loss 0.9945, time 4.41ms, mfu 11.19%
iter 1190: loss 1.0008, time 4.53ms, mfu 11.19%
iter 1200: loss 0.9507, time 4.61ms, mfu 11.17%
iter 1210: loss 0.9930, time 4.44ms, mfu 11.19%
iter 1220: loss 0.9698, time 4.48ms, mfu 11.20%
iter 1230: loss 0.9638, time 4.66ms, mfu 11.16%
iter 1240: loss 1.0146, time 4.52ms, mfu 11.16%
step 1250: train loss 0.9603, val loss 0.9609
saving checkpoint to out-experiment2_width-n_embd_128
iter 1250: loss 0.9502, time 1037.74ms, mfu 10.05%
iter 1260: loss 0.9225, time 4.50ms, mfu 10.17%
iter 1270: loss 0.9680, time 4.60ms, mfu 10.25%
iter 1280: loss 0.9760, time 4.53ms, mfu 10.34%
iter 1290: loss 0.9469, time 4.54ms, mfu 10.42%
iter 1300: loss 0.9092, time 4.50ms, mfu 10.50%
iter 1310: loss 0.9660, time 4.47ms, mfu 10.58%
iter 1320: loss 0.9767, time 4.44ms, mfu 10.66%
iter 1330: loss 0.9232, time 4.51ms, mfu 10.72%
iter 1340: loss 0.9373, time 4.27ms, mfu 10.83%
iter 1350: loss 0.9238, time 4.43ms, mfu 10.89%
iter 1360: loss 0.9444, time 4.49ms, mfu 10.92%
iter 1370: loss 0.9086, time 4.49ms, mfu 10.96%
iter 1380: loss 0.9466, time 4.52ms, mfu 10.98%
iter 1390: loss 0.9513, time 4.45ms, mfu 11.02%
iter 1400: loss 0.9320, time 4.57ms, mfu 11.02%
iter 1410: loss 0.9159, time 4.35ms, mfu 11.08%
iter 1420: loss 0.9141, time 4.43ms, mfu 11.11%
iter 1430: loss 0.9030, time 4.65ms, mfu 11.09%
iter 1440: loss 0.9809, time 4.31ms, mfu 11.15%
iter 1450: loss 0.9203, time 4.31ms, mfu 11.21%
iter 1460: loss 0.9202, time 4.46ms, mfu 11.22%
iter 1470: loss 0.9429, time 4.44ms, mfu 11.24%
iter 1480: loss 0.9335, time 4.45ms, mfu 11.25%
iter 1490: loss 0.9474, time 4.61ms, mfu 11.22%
step 1500: train loss 0.9141, val loss 0.9128
saving checkpoint to out-experiment2_width-n_embd_128
iter 1500: loss 0.9473, time 1030.99ms, mfu 10.10%
iter 1510: loss 0.9179, time 7.00ms, mfu 9.81%
iter 1520: loss 0.8638, time 4.51ms, mfu 9.95%
iter 1530: loss 0.9703, time 4.47ms, mfu 10.09%
iter 1540: loss 0.9256, time 4.65ms, mfu 10.17%
iter 1550: loss 0.8571, time 4.56ms, mfu 10.26%
iter 1560: loss 0.9246, time 4.55ms, mfu 10.34%
iter 1570: loss 0.9106, time 4.58ms, mfu 10.41%
iter 1580: loss 0.9427, time 4.61ms, mfu 10.47%
iter 1590: loss 0.8566, time 4.64ms, mfu 10.51%
iter 1600: loss 0.8830, time 4.50ms, mfu 10.58%
iter 1610: loss 0.8698, time 4.53ms, mfu 10.64%
iter 1620: loss 0.9078, time 4.61ms, mfu 10.67%
iter 1630: loss 0.9162, time 4.47ms, mfu 10.73%
iter 1640: loss 0.9200, time 4.73ms, mfu 10.73%
iter 1650: loss 0.8757, time 4.45ms, mfu 10.79%
iter 1660: loss 0.8514, time 4.68ms, mfu 10.79%
iter 1670: loss 0.8777, time 4.66ms, mfu 10.80%
iter 1680: loss 0.8533, time 4.44ms, mfu 10.85%
iter 1690: loss 0.8873, time 4.28ms, mfu 10.95%
iter 1700: loss 0.9054, time 4.57ms, mfu 10.96%
iter 1710: loss 0.8878, time 4.51ms, mfu 10.98%
iter 1720: loss 0.8619, time 4.76ms, mfu 10.95%
iter 1730: loss 0.8980, time 4.47ms, mfu 10.98%
iter 1740: loss 0.8657, time 4.43ms, mfu 11.03%
step 1750: train loss 0.8780, val loss 0.8786
saving checkpoint to out-experiment2_width-n_embd_128
iter 1750: loss 0.9039, time 1041.38ms, mfu 9.93%
iter 1760: loss 0.8795, time 4.49ms, mfu 10.06%
iter 1770: loss 0.8885, time 4.44ms, mfu 10.19%
iter 1780: loss 0.8848, time 4.44ms, mfu 10.31%
iter 1790: loss 0.8611, time 4.69ms, mfu 10.36%
iter 1800: loss 0.8478, time 4.49ms, mfu 10.45%
iter 1810: loss 0.8071, time 4.23ms, mfu 10.60%
iter 1820: loss 0.8985, time 4.21ms, mfu 10.74%
iter 1830: loss 0.8385, time 4.20ms, mfu 10.87%
iter 1840: loss 0.9169, time 4.62ms, mfu 10.87%
iter 1850: loss 0.8075, time 4.51ms, mfu 10.91%
iter 1860: loss 0.8492, time 4.55ms, mfu 10.93%
iter 1870: loss 0.8541, time 4.53ms, mfu 10.95%
iter 1880: loss 0.8818, time 4.49ms, mfu 10.98%
iter 1890: loss 0.8934, time 4.48ms, mfu 11.01%
iter 1900: loss 0.8577, time 4.55ms, mfu 11.02%
iter 1910: loss 0.8560, time 4.22ms, mfu 11.11%
iter 1920: loss 0.8637, time 4.44ms, mfu 11.14%
iter 1930: loss 0.8402, time 4.62ms, mfu 11.12%
iter 1940: loss 0.8217, time 4.53ms, mfu 11.12%
iter 1950: loss 0.8386, time 4.51ms, mfu 11.13%
iter 1960: loss 0.8585, time 4.49ms, mfu 11.14%
iter 1970: loss 0.8866, time 4.47ms, mfu 11.16%
iter 1980: loss 0.8233, time 4.43ms, mfu 11.18%
iter 1990: loss 0.8002, time 4.29ms, mfu 11.24%
step 2000: train loss 0.8402, val loss 0.8438
saving checkpoint to out-experiment2_width-n_embd_128
iter 2000: loss 0.8465, time 1047.70ms, mfu 10.12%
iter 2010: loss 0.8419, time 4.48ms, mfu 10.24%
iter 2020: loss 0.8521, time 4.47ms, mfu 10.35%
iter 2030: loss 0.8249, time 4.54ms, mfu 10.42%
iter 2040: loss 0.8651, time 4.89ms, mfu 10.42%
iter 2050: loss 0.8573, time 4.60ms, mfu 10.47%
iter 2060: loss 0.8450, time 4.47ms, mfu 10.56%
iter 2070: loss 0.8545, time 4.23ms, mfu 10.70%
iter 2080: loss 0.8295, time 4.23ms, mfu 10.82%
iter 2090: loss 0.8339, time 4.25ms, mfu 10.93%
iter 2100: loss 0.8577, time 4.24ms, mfu 11.03%
iter 2110: loss 0.8071, time 4.46ms, mfu 11.06%
iter 2120: loss 0.8047, time 4.62ms, mfu 11.05%
iter 2130: loss 0.8379, time 4.47ms, mfu 11.07%
iter 2140: loss 0.7976, time 4.50ms, mfu 11.09%
iter 2150: loss 0.7970, time 4.59ms, mfu 11.08%
iter 2160: loss 0.8273, time 4.48ms, mfu 11.10%
iter 2170: loss 0.8155, time 4.22ms, mfu 11.19%
iter 2180: loss 0.8462, time 4.20ms, mfu 11.27%
iter 2190: loss 0.8361, time 4.26ms, mfu 11.33%
iter 2200: loss 0.8413, time 4.19ms, mfu 11.40%
iter 2210: loss 0.8069, time 4.53ms, mfu 11.38%
iter 2220: loss 0.8302, time 4.59ms, mfu 11.34%
iter 2230: loss 0.8355, time 4.36ms, mfu 11.37%
iter 2240: loss 0.7782, time 4.48ms, mfu 11.36%
step 2250: train loss 0.8190, val loss 0.8167
saving checkpoint to out-experiment2_width-n_embd_128
iter 2250: loss 0.7880, time 1029.35ms, mfu 10.23%
iter 2260: loss 0.7860, time 4.65ms, mfu 10.29%
iter 2270: loss 0.8296, time 4.55ms, mfu 10.37%
iter 2280: loss 0.8060, time 4.47ms, mfu 10.47%
iter 2290: loss 0.8100, time 4.25ms, mfu 10.61%
iter 2300: loss 0.8630, time 4.26ms, mfu 10.73%
iter 2310: loss 0.7777, time 4.58ms, mfu 10.76%
iter 2320: loss 0.7993, time 4.53ms, mfu 10.80%
iter 2330: loss 0.7983, time 4.28ms, mfu 10.91%
iter 2340: loss 0.8215, time 4.47ms, mfu 10.94%
iter 2350: loss 0.8196, time 5.73ms, mfu 10.73%
iter 2360: loss 0.8499, time 4.64ms, mfu 10.75%
iter 2370: loss 0.8051, time 4.60ms, mfu 10.77%
iter 2380: loss 0.8173, time 4.53ms, mfu 10.81%
iter 2390: loss 0.8186, time 4.54ms, mfu 10.84%
iter 2400: loss 0.8109, time 4.74ms, mfu 10.82%
iter 2410: loss 0.8029, time 6.89ms, mfu 10.47%
iter 2420: loss 0.7786, time 4.61ms, mfu 10.52%
iter 2430: loss 0.8144, time 4.95ms, mfu 10.49%
iter 2440: loss 0.8212, time 7.19ms, mfu 10.14%
iter 2450: loss 0.7839, time 4.48ms, mfu 10.26%
iter 2460: loss 0.8151, time 4.27ms, mfu 10.42%
iter 2470: loss 0.7952, time 4.70ms, mfu 10.45%
iter 2480: loss 0.8155, time 4.23ms, mfu 10.60%
iter 2490: loss 0.7927, time 4.46ms, mfu 10.67%
step 2500: train loss 0.7954, val loss 0.7933
saving checkpoint to out-experiment2_width-n_embd_128
iter 2500: loss 0.7846, time 1017.97ms, mfu 9.61%
iter 2510: loss 0.7939, time 4.68ms, mfu 9.73%
iter 2520: loss 0.7981, time 4.28ms, mfu 9.93%
iter 2530: loss 0.7677, time 4.26ms, mfu 10.13%
iter 2540: loss 0.7924, time 4.38ms, mfu 10.27%
iter 2550: loss 0.7978, time 4.53ms, mfu 10.36%
iter 2560: loss 0.8036, time 4.37ms, mfu 10.48%
iter 2570: loss 0.7911, time 4.35ms, mfu 10.59%
iter 2580: loss 0.7966, time 4.51ms, mfu 10.65%
iter 2590: loss 0.8169, time 4.23ms, mfu 10.78%
iter 2600: loss 0.8076, time 4.53ms, mfu 10.82%
iter 2610: loss 0.7542, time 4.31ms, mfu 10.91%
iter 2620: loss 0.8140, time 4.63ms, mfu 10.91%
iter 2630: loss 0.8295, time 4.33ms, mfu 10.98%
iter 2640: loss 0.8229, time 4.39ms, mfu 11.04%
iter 2650: loss 0.8246, time 4.59ms, mfu 11.03%
iter 2660: loss 0.7928, time 4.70ms, mfu 11.01%
iter 2670: loss 0.7670, time 4.65ms, mfu 10.99%
iter 2680: loss 0.7741, time 4.74ms, mfu 10.96%
iter 2690: loss 0.7777, time 4.58ms, mfu 10.96%
iter 2700: loss 0.7705, time 4.60ms, mfu 10.97%
iter 2710: loss 0.7661, time 4.33ms, mfu 11.04%
iter 2720: loss 0.8265, time 4.36ms, mfu 11.09%
iter 2730: loss 0.7718, time 4.64ms, mfu 11.07%
iter 2740: loss 0.7881, time 4.57ms, mfu 11.07%
step 2750: train loss 0.7791, val loss 0.7794
saving checkpoint to out-experiment2_width-n_embd_128
iter 2750: loss 0.7332, time 1033.94ms, mfu 9.97%
iter 2760: loss 0.7963, time 4.34ms, mfu 10.13%
iter 2770: loss 0.7594, time 4.59ms, mfu 10.22%
iter 2780: loss 0.7621, time 4.35ms, mfu 10.36%
iter 2790: loss 0.7527, time 4.72ms, mfu 10.40%
iter 2800: loss 0.7849, time 4.35ms, mfu 10.52%
iter 2810: loss 0.7389, time 4.45ms, mfu 10.60%
iter 2820: loss 0.8067, time 4.54ms, mfu 10.66%
iter 2830: loss 0.7355, time 4.78ms, mfu 10.65%
iter 2840: loss 0.7450, time 4.46ms, mfu 10.71%
iter 2850: loss 0.7824, time 4.52ms, mfu 10.76%
iter 2860: loss 0.7996, time 4.36ms, mfu 10.85%
iter 2870: loss 0.7913, time 4.36ms, mfu 10.92%
iter 2880: loss 0.7637, time 4.63ms, mfu 10.92%
iter 2890: loss 0.7588, time 4.36ms, mfu 10.99%
iter 2900: loss 0.7907, time 4.70ms, mfu 10.96%
iter 2910: loss 0.7631, time 4.37ms, mfu 11.02%
iter 2920: loss 0.7869, time 4.62ms, mfu 11.01%
iter 2930: loss 0.7926, time 4.63ms, mfu 11.00%
iter 2940: loss 0.7853, time 4.67ms, mfu 10.98%
iter 2950: loss 0.7734, time 4.40ms, mfu 11.04%
iter 2960: loss 0.7948, time 4.72ms, mfu 11.00%
iter 2970: loss 0.7431, time 4.33ms, mfu 11.07%
iter 2980: loss 0.7875, time 4.41ms, mfu 11.11%
iter 2990: loss 0.7812, time 4.57ms, mfu 11.10%
step 3000: train loss 0.7632, val loss 0.7616
saving checkpoint to out-experiment2_width-n_embd_128
iter 3000: loss 0.7798, time 1049.67ms, mfu 10.00%
iter 3010: loss 0.7700, time 4.37ms, mfu 10.15%
iter 3020: loss 0.7299, time 4.59ms, mfu 10.24%
iter 3030: loss 0.7795, time 4.34ms, mfu 10.38%
iter 3040: loss 0.7683, time 4.64ms, mfu 10.43%
iter 3050: loss 0.7528, time 4.33ms, mfu 10.56%
iter 3060: loss 0.7356, time 4.36ms, mfu 10.66%
iter 3070: loss 0.7728, time 4.39ms, mfu 10.74%
iter 3080: loss 0.7600, time 4.69ms, mfu 10.75%
iter 3090: loss 0.7734, time 4.48ms, mfu 10.80%
iter 3100: loss 0.8053, time 4.36ms, mfu 10.88%
iter 3110: loss 0.7762, time 4.72ms, mfu 10.86%
iter 3120: loss 0.7251, time 4.33ms, mfu 10.94%
iter 3130: loss 0.7597, time 4.58ms, mfu 10.95%
iter 3140: loss 0.7694, time 4.73ms, mfu 10.92%
iter 3150: loss 0.7701, time 4.61ms, mfu 10.93%
iter 3160: loss 0.7592, time 4.46ms, mfu 10.97%
iter 3170: loss 0.7219, time 4.36ms, mfu 11.03%
iter 3180: loss 0.7277, time 4.34ms, mfu 11.09%
iter 3190: loss 0.7340, time 4.44ms, mfu 11.12%
iter 3200: loss 0.7493, time 4.58ms, mfu 11.11%
iter 3210: loss 0.7607, time 4.34ms, mfu 11.16%
iter 3220: loss 0.7632, time 4.54ms, mfu 11.16%
iter 3230: loss 0.7279, time 4.47ms, mfu 11.18%
iter 3240: loss 0.7383, time 4.61ms, mfu 11.16%
step 3250: train loss 0.7472, val loss 0.7507
saving checkpoint to out-experiment2_width-n_embd_128
iter 3250: loss 0.7513, time 1029.60ms, mfu 10.04%
iter 3260: loss 0.7381, time 4.64ms, mfu 10.13%
iter 3270: loss 0.7239, time 4.38ms, mfu 10.27%
iter 3280: loss 0.7440, time 4.36ms, mfu 10.40%
iter 3290: loss 0.7806, time 4.56ms, mfu 10.47%
iter 3300: loss 0.7262, time 4.68ms, mfu 10.50%
iter 3310: loss 0.7362, time 4.44ms, mfu 10.59%
iter 3320: loss 0.7381, time 4.64ms, mfu 10.62%
iter 3330: loss 0.7646, time 4.55ms, mfu 10.67%
iter 3340: loss 0.7193, time 4.71ms, mfu 10.68%
iter 3350: loss 0.7256, time 4.53ms, mfu 10.72%
iter 3360: loss 0.7644, time 4.34ms, mfu 10.82%
iter 3370: loss 0.7928, time 4.38ms, mfu 10.89%
iter 3380: loss 0.7218, time 4.35ms, mfu 10.96%
iter 3390: loss 0.7430, time 4.32ms, mfu 11.04%
iter 3400: loss 0.7833, time 4.82ms, mfu 10.98%
iter 3410: loss 0.7590, time 4.62ms, mfu 10.98%
iter 3420: loss 0.7257, time 4.65ms, mfu 10.97%
iter 3430: loss 0.7639, time 4.61ms, mfu 10.96%
iter 3440: loss 0.7419, time 4.72ms, mfu 10.94%
iter 3450: loss 0.7391, time 4.69ms, mfu 10.92%
iter 3460: loss 0.7289, time 4.69ms, mfu 10.91%
iter 3470: loss 0.7665, time 4.59ms, mfu 10.92%
iter 3480: loss 0.7296, time 4.56ms, mfu 10.93%
iter 3490: loss 0.7410, time 4.61ms, mfu 10.94%
step 3500: train loss 0.7402, val loss 0.7348
saving checkpoint to out-experiment2_width-n_embd_128
iter 3500: loss 0.7141, time 1046.45ms, mfu 9.85%
iter 3510: loss 0.7139, time 4.54ms, mfu 9.98%
iter 3520: loss 0.7268, time 4.75ms, mfu 10.04%
iter 3530: loss 0.7415, time 4.65ms, mfu 10.12%
iter 3540: loss 0.7179, time 4.65ms, mfu 10.20%
iter 3550: loss 0.7097, time 4.68ms, mfu 10.26%
iter 3560: loss 0.7017, time 4.62ms, mfu 10.33%
iter 3570: loss 0.7189, time 4.45ms, mfu 10.43%
iter 3580: loss 0.7173, time 4.61ms, mfu 10.48%
iter 3590: loss 0.7431, time 4.62ms, mfu 10.53%
iter 3600: loss 0.7202, time 4.70ms, mfu 10.55%
iter 3610: loss 0.7464, time 4.50ms, mfu 10.62%
iter 3620: loss 0.7241, time 4.57ms, mfu 10.66%
iter 3630: loss 0.7288, time 4.64ms, mfu 10.69%
iter 3640: loss 0.7155, time 4.65ms, mfu 10.70%
iter 3650: loss 0.7163, time 4.60ms, mfu 10.73%
iter 3660: loss 0.7412, time 4.57ms, mfu 10.77%
iter 3670: loss 0.7214, time 4.60ms, mfu 10.79%
iter 3680: loss 0.7146, time 4.51ms, mfu 10.83%
iter 3690: loss 0.6948, time 4.61ms, mfu 10.84%
iter 3700: loss 0.7492, time 4.64ms, mfu 10.85%
iter 3710: loss 0.7603, time 4.57ms, mfu 10.87%
iter 3720: loss 0.7589, time 4.42ms, mfu 10.93%
iter 3730: loss 0.7211, time 4.35ms, mfu 10.99%
iter 3740: loss 0.6894, time 4.36ms, mfu 11.05%
step 3750: train loss 0.7297, val loss 0.7273
saving checkpoint to out-experiment2_width-n_embd_128
iter 3750: loss 0.7282, time 1028.83ms, mfu 9.95%
iter 3760: loss 0.7567, time 4.56ms, mfu 10.07%
iter 3770: loss 0.7383, time 4.39ms, mfu 10.21%
iter 3780: loss 0.7154, time 4.35ms, mfu 10.35%
iter 3790: loss 0.7490, time 4.36ms, mfu 10.47%
iter 3800: loss 0.7533, time 4.63ms, mfu 10.52%
iter 3810: loss 0.7161, time 4.64ms, mfu 10.56%
iter 3820: loss 0.7236, time 4.47ms, mfu 10.63%
iter 3830: loss 0.7205, time 4.75ms, mfu 10.63%
iter 3840: loss 0.7732, time 4.34ms, mfu 10.73%
iter 3850: loss 0.7632, time 4.35ms, mfu 10.82%
iter 3860: loss 0.7215, time 4.59ms, mfu 10.84%
iter 3870: loss 0.7428, time 4.71ms, mfu 10.83%
iter 3880: loss 0.7076, time 4.59ms, mfu 10.85%
iter 3890: loss 0.7134, time 4.34ms, mfu 10.93%
iter 3900: loss 0.7266, time 4.37ms, mfu 10.99%
iter 3910: loss 0.7105, time 4.61ms, mfu 10.99%
iter 3920: loss 0.7182, time 4.58ms, mfu 10.99%
iter 3930: loss 0.7054, time 4.36ms, mfu 11.05%
iter 3940: loss 0.7221, time 4.57ms, mfu 11.05%
iter 3950: loss 0.7371, time 4.30ms, mfu 11.12%
iter 3960: loss 0.7238, time 4.60ms, mfu 11.11%
iter 3970: loss 0.7273, time 4.50ms, mfu 11.12%
iter 3980: loss 0.7234, time 4.34ms, mfu 11.17%
iter 3990: loss 0.7130, time 4.35ms, mfu 11.22%
step 4000: train loss 0.7193, val loss 0.7189
saving checkpoint to out-experiment2_width-n_embd_128
iter 4000: loss 0.6869, time 1040.72ms, mfu 10.10%
iter 4010: loss 0.6865, time 4.64ms, mfu 10.18%
iter 4020: loss 0.7403, time 4.59ms, mfu 10.26%
iter 4030: loss 0.7356, time 4.33ms, mfu 10.40%
iter 4040: loss 0.7104, time 4.40ms, mfu 10.51%
iter 4050: loss 0.7538, time 4.46ms, mfu 10.59%
iter 4060: loss 0.7163, time 4.66ms, mfu 10.62%
iter 4070: loss 0.7467, time 4.53ms, mfu 10.67%
iter 4080: loss 0.7169, time 4.42ms, mfu 10.74%
iter 4090: loss 0.7229, time 4.59ms, mfu 10.77%
iter 4100: loss 0.6782, time 4.58ms, mfu 10.80%
iter 4110: loss 0.6999, time 4.57ms, mfu 10.82%
iter 4120: loss 0.7270, time 4.69ms, mfu 10.82%
iter 4130: loss 0.6953, time 4.42ms, mfu 10.88%
iter 4140: loss 0.7210, time 4.34ms, mfu 10.95%
iter 4150: loss 0.6923, time 4.39ms, mfu 11.01%
iter 4160: loss 0.7150, time 4.65ms, mfu 11.00%
iter 4170: loss 0.7341, time 4.61ms, mfu 10.99%
iter 4180: loss 0.7156, time 4.36ms, mfu 11.05%
iter 4190: loss 0.7035, time 4.49ms, mfu 11.07%
iter 4200: loss 0.7053, time 4.40ms, mfu 11.11%
iter 4210: loss 0.6903, time 4.52ms, mfu 11.12%
iter 4220: loss 0.6909, time 4.62ms, mfu 11.10%
iter 4230: loss 0.6928, time 4.66ms, mfu 11.08%
iter 4240: loss 0.7098, time 4.62ms, mfu 11.06%
step 4250: train loss 0.7126, val loss 0.7118
saving checkpoint to out-experiment2_width-n_embd_128
iter 4250: loss 0.7021, time 1027.04ms, mfu 9.96%
iter 4260: loss 0.6922, time 4.71ms, mfu 10.04%
iter 4270: loss 0.7196, time 4.62ms, mfu 10.13%
iter 4280: loss 0.7293, time 4.71ms, mfu 10.19%
iter 4290: loss 0.6994, time 4.63ms, mfu 10.26%
iter 4300: loss 0.7034, time 4.72ms, mfu 10.30%
iter 4310: loss 0.7047, time 4.35ms, mfu 10.43%
iter 4320: loss 0.7158, time 4.70ms, mfu 10.47%
iter 4330: loss 0.7198, time 4.61ms, mfu 10.52%
iter 4340: loss 0.7067, time 4.34ms, mfu 10.63%
iter 4350: loss 0.7050, time 4.37ms, mfu 10.72%
iter 4360: loss 0.6939, time 4.34ms, mfu 10.82%
iter 4370: loss 0.7371, time 4.46ms, mfu 10.87%
iter 4380: loss 0.7374, time 4.59ms, mfu 10.88%
iter 4390: loss 0.6915, time 4.59ms, mfu 10.89%
iter 4400: loss 0.7075, time 4.65ms, mfu 10.89%
iter 4410: loss 0.7308, time 4.58ms, mfu 10.91%
iter 4420: loss 0.6994, time 4.62ms, mfu 10.91%
iter 4430: loss 0.7037, time 4.40ms, mfu 10.97%
iter 4440: loss 0.7112, time 4.79ms, mfu 10.92%
iter 4450: loss 0.7101, time 4.59ms, mfu 10.93%
iter 4460: loss 0.7022, time 4.32ms, mfu 11.01%
iter 4470: loss 0.7074, time 4.62ms, mfu 11.00%
iter 4480: loss 0.7332, time 4.64ms, mfu 10.99%
iter 4490: loss 0.6928, time 4.45ms, mfu 11.03%
step 4500: train loss 0.7038, val loss 0.7043
saving checkpoint to out-experiment2_width-n_embd_128
iter 4500: loss 0.7162, time 1051.65ms, mfu 9.93%
iter 4510: loss 0.6962, time 4.74ms, mfu 10.00%
iter 4520: loss 0.6950, time 4.77ms, mfu 10.06%
iter 4530: loss 0.6695, time 4.64ms, mfu 10.15%
iter 4540: loss 0.7129, time 4.37ms, mfu 10.29%
iter 4550: loss 0.7018, time 4.64ms, mfu 10.35%
iter 4560: loss 0.7158, time 4.64ms, mfu 10.40%
iter 4570: loss 0.7039, time 4.37ms, mfu 10.52%
iter 4580: loss 0.6718, time 4.63ms, mfu 10.56%
iter 4590: loss 0.7111, time 4.82ms, mfu 10.55%
iter 4600: loss 0.6956, time 4.48ms, mfu 10.62%
iter 4610: loss 0.6884, time 4.63ms, mfu 10.65%
iter 4620: loss 0.7014, time 4.70ms, mfu 10.66%
iter 4630: loss 0.7511, time 4.61ms, mfu 10.69%
iter 4640: loss 0.6965, time 4.67ms, mfu 10.70%
iter 4650: loss 0.6847, time 4.34ms, mfu 10.80%
iter 4660: loss 0.7041, time 4.62ms, mfu 10.81%
iter 4670: loss 0.6789, time 4.58ms, mfu 10.83%
iter 4680: loss 0.7035, time 4.61ms, mfu 10.85%
iter 4690: loss 0.7154, time 4.51ms, mfu 10.88%
iter 4700: loss 0.6808, time 4.53ms, mfu 10.91%
iter 4710: loss 0.7326, time 4.35ms, mfu 10.98%
iter 4720: loss 0.6742, time 4.46ms, mfu 11.01%
iter 4730: loss 0.6923, time 4.58ms, mfu 11.02%
iter 4740: loss 0.6885, time 4.61ms, mfu 11.01%
step 4750: train loss 0.7000, val loss 0.7008
saving checkpoint to out-experiment2_width-n_embd_128
iter 4750: loss 0.6868, time 1028.12ms, mfu 9.91%
iter 4760: loss 0.7331, time 4.33ms, mfu 10.09%
iter 4770: loss 0.6789, time 4.62ms, mfu 10.17%
iter 4780: loss 0.7023, time 4.69ms, mfu 10.23%
iter 4790: loss 0.6860, time 4.62ms, mfu 10.30%
iter 4800: loss 0.7146, time 4.44ms, mfu 10.41%
iter 4810: loss 0.7022, time 4.71ms, mfu 10.44%
iter 4820: loss 0.6768, time 4.36ms, mfu 10.56%
iter 4830: loss 0.7149, time 4.60ms, mfu 10.60%
iter 4840: loss 0.6828, time 4.60ms, mfu 10.64%
iter 4850: loss 0.7046, time 4.38ms, mfu 10.73%
iter 4860: loss 0.7235, time 4.61ms, mfu 10.75%
iter 4870: loss 0.7508, time 4.63ms, mfu 10.77%
iter 4880: loss 0.6960, time 4.62ms, mfu 10.79%
iter 4890: loss 0.6766, time 4.55ms, mfu 10.82%
iter 4900: loss 0.7136, time 4.62ms, mfu 10.83%
iter 4910: loss 0.6748, time 4.63ms, mfu 10.84%
iter 4920: loss 0.6847, time 4.58ms, mfu 10.86%
iter 4930: loss 0.6935, time 4.34ms, mfu 10.94%
iter 4940: loss 0.7326, time 4.77ms, mfu 10.90%
iter 4950: loss 0.6905, time 4.38ms, mfu 10.97%
iter 4960: loss 0.6994, time 4.55ms, mfu 10.98%
iter 4970: loss 0.7192, time 4.58ms, mfu 10.99%
iter 4980: loss 0.7238, time 4.35ms, mfu 11.05%
iter 4990: loss 0.6779, time 4.33ms, mfu 11.11%
step 5000: train loss 0.6979, val loss 0.6989
saving checkpoint to out-experiment2_width-n_embd_128
iter 5000: loss 0.6760, time 1036.09ms, mfu 10.00%


STDERR:
/data/lst141/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
