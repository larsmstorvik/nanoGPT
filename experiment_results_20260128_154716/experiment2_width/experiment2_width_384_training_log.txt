Overriding config with config/train_tinystories.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-experiment2_width-n_embd_384'
eval_interval = 250
eval_iters = 200
log_interval = 10

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False
wandb_project = 'tinystories'
wandb_run_name = 'experiment2_width_n_embd_384'

dataset = 'tinystories'
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256

# baby GPT model :)
n_layer = 6
n_head = 8
n_embd = 384
dropout = 0.0

learning_rate = 0.001
max_iters = 5000
lr_decay_iters = 5000
min_lr = 0.0001
beta2 = 0.99

warmup_iters = 100

device = 'cuda:1'

tokens per iteration will be: 16,384
found vocab_size = 228 (inside data/tinystories/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.71M
num decayed parameter tensors: 26, with 10,802,688 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 5.4897, val loss 5.4896
iter 0: loss 5.4945, time 10949.37ms, mfu -100.00%
iter 10: loss 3.5336, time 8.55ms, mfu 43.83%
iter 20: loss 2.9175, time 9.19ms, mfu 43.52%
iter 30: loss 2.5254, time 9.20ms, mfu 43.24%
iter 40: loss 2.3971, time 9.27ms, mfu 42.95%
iter 50: loss 2.3263, time 9.28ms, mfu 42.69%
iter 60: loss 2.3314, time 9.35ms, mfu 42.43%
iter 70: loss 2.3004, time 9.30ms, mfu 42.22%
iter 80: loss 2.2718, time 9.34ms, mfu 42.01%
iter 90: loss 2.2515, time 11.81ms, mfu 40.98%
iter 100: loss 2.1701, time 9.37ms, mfu 40.88%
iter 110: loss 2.1504, time 9.21ms, mfu 40.86%
iter 120: loss 2.1260, time 9.25ms, mfu 40.82%
iter 130: loss 2.0694, time 9.23ms, mfu 40.80%
iter 140: loss 2.0170, time 9.27ms, mfu 40.76%
iter 150: loss 1.8902, time 9.28ms, mfu 40.72%
iter 160: loss 1.8825, time 9.31ms, mfu 40.67%
iter 170: loss 1.8060, time 9.29ms, mfu 40.64%
iter 180: loss 1.6942, time 9.25ms, mfu 40.62%
iter 190: loss 1.6856, time 9.41ms, mfu 40.54%
iter 200: loss 1.5651, time 9.22ms, mfu 40.55%
iter 210: loss 1.5414, time 9.27ms, mfu 40.53%
iter 220: loss 1.5229, time 9.18ms, mfu 40.56%
iter 230: loss 1.4839, time 9.31ms, mfu 40.53%
iter 240: loss 1.4142, time 9.31ms, mfu 40.50%
step 250: train loss 1.4167, val loss 1.4126
saving checkpoint to out-experiment2_width-n_embd_384
iter 250: loss 1.3953, time 1736.10ms, mfu 36.47%
iter 260: loss 1.3373, time 8.58ms, mfu 37.19%
iter 270: loss 1.3604, time 9.28ms, mfu 37.51%
iter 280: loss 1.3229, time 9.19ms, mfu 37.83%
iter 290: loss 1.2601, time 9.22ms, mfu 38.11%
iter 300: loss 1.2746, time 9.31ms, mfu 38.32%
iter 310: loss 1.2433, time 9.30ms, mfu 38.52%
iter 320: loss 1.2009, time 9.33ms, mfu 38.68%
iter 330: loss 1.1844, time 9.22ms, mfu 38.88%
iter 340: loss 1.1959, time 9.29ms, mfu 39.03%
iter 350: loss 1.1769, time 9.35ms, mfu 39.13%
iter 360: loss 1.1760, time 9.44ms, mfu 39.18%
iter 370: loss 1.1294, time 9.22ms, mfu 39.33%
iter 380: loss 1.0631, time 9.29ms, mfu 39.43%
iter 390: loss 1.1271, time 9.30ms, mfu 39.51%
iter 400: loss 1.0931, time 9.43ms, mfu 39.53%
iter 410: loss 1.1037, time 9.33ms, mfu 39.59%
iter 420: loss 1.0623, time 9.27ms, mfu 39.68%
iter 430: loss 1.0384, time 9.26ms, mfu 39.75%
iter 440: loss 1.0559, time 9.24ms, mfu 39.83%
iter 450: loss 1.0834, time 9.23ms, mfu 39.91%
iter 460: loss 1.0560, time 9.44ms, mfu 39.89%
iter 470: loss 1.0098, time 9.33ms, mfu 39.91%
iter 480: loss 1.0321, time 9.29ms, mfu 39.95%
iter 490: loss 0.9896, time 9.21ms, mfu 40.03%
step 500: train loss 0.9810, val loss 0.9849
saving checkpoint to out-experiment2_width-n_embd_384
iter 500: loss 0.9914, time 2556.62ms, mfu 36.04%
iter 510: loss 0.9726, time 6.23ms, mfu 38.44%
iter 520: loss 0.9965, time 9.34ms, mfu 38.61%
iter 530: loss 0.9217, time 9.20ms, mfu 38.82%
iter 540: loss 0.9448, time 9.33ms, mfu 38.95%
iter 550: loss 0.9466, time 9.34ms, mfu 39.07%
iter 560: loss 0.9445, time 9.27ms, mfu 39.21%
iter 570: loss 0.9338, time 9.42ms, mfu 39.26%
iter 580: loss 0.9428, time 9.35ms, mfu 39.34%
iter 590: loss 0.9460, time 9.37ms, mfu 39.40%
iter 600: loss 0.9102, time 9.32ms, mfu 39.48%
iter 610: loss 0.9246, time 9.44ms, mfu 39.50%
iter 620: loss 0.9067, time 9.49ms, mfu 39.50%
iter 630: loss 0.8898, time 9.30ms, mfu 39.57%
iter 640: loss 0.8806, time 9.48ms, mfu 39.57%
iter 650: loss 0.8909, time 9.40ms, mfu 39.60%
iter 660: loss 0.9054, time 9.35ms, mfu 39.64%
iter 670: loss 0.8667, time 9.43ms, mfu 39.65%
iter 680: loss 0.8811, time 9.40ms, mfu 39.67%
iter 690: loss 0.8685, time 9.35ms, mfu 39.71%
iter 700: loss 0.8546, time 9.39ms, mfu 39.73%
iter 710: loss 0.8603, time 9.44ms, mfu 39.72%
iter 720: loss 0.8609, time 9.40ms, mfu 39.74%
iter 730: loss 0.8533, time 9.40ms, mfu 39.75%
iter 740: loss 0.8200, time 9.41ms, mfu 39.75%
step 750: train loss 0.8442, val loss 0.8445
saving checkpoint to out-experiment2_width-n_embd_384
iter 750: loss 0.8222, time 2501.34ms, mfu 35.79%
iter 760: loss 0.8409, time 7.03ms, mfu 37.54%
iter 770: loss 0.8336, time 9.32ms, mfu 37.81%
iter 780: loss 0.8651, time 9.19ms, mfu 38.10%
iter 790: loss 0.8353, time 9.40ms, mfu 38.28%
iter 800: loss 0.8356, time 9.30ms, mfu 38.48%
iter 810: loss 0.8281, time 9.30ms, mfu 38.66%
iter 820: loss 0.8227, time 9.34ms, mfu 38.80%
iter 830: loss 0.8508, time 9.40ms, mfu 38.90%
iter 840: loss 0.8331, time 9.37ms, mfu 39.01%
iter 850: loss 0.8006, time 9.55ms, mfu 39.04%
iter 860: loss 0.7691, time 9.40ms, mfu 39.12%
iter 870: loss 0.8118, time 9.36ms, mfu 39.21%
iter 880: loss 0.8335, time 9.47ms, mfu 39.24%
iter 890: loss 0.8038, time 9.39ms, mfu 39.31%
iter 900: loss 0.7953, time 9.37ms, mfu 39.37%
iter 910: loss 0.7952, time 9.38ms, mfu 39.43%
iter 920: loss 0.7266, time 9.36ms, mfu 39.49%
iter 930: loss 0.7900, time 9.37ms, mfu 39.54%
iter 940: loss 0.8520, time 9.41ms, mfu 39.57%
iter 950: loss 0.7728, time 9.43ms, mfu 39.58%
iter 960: loss 0.7831, time 9.53ms, mfu 39.55%
iter 970: loss 0.8085, time 9.37ms, mfu 39.60%
iter 980: loss 0.7974, time 9.26ms, mfu 39.68%
iter 990: loss 0.7912, time 9.41ms, mfu 39.69%
step 1000: train loss 0.7783, val loss 0.7746
saving checkpoint to out-experiment2_width-n_embd_384
iter 1000: loss 0.7927, time 2488.07ms, mfu 35.74%
iter 1010: loss 0.7858, time 6.93ms, mfu 37.57%
iter 1020: loss 0.7473, time 9.32ms, mfu 37.83%
iter 1030: loss 0.7525, time 9.14ms, mfu 38.15%
iter 1040: loss 0.7448, time 9.35ms, mfu 38.34%
iter 1050: loss 0.7564, time 9.38ms, mfu 38.50%
iter 1060: loss 0.7717, time 9.47ms, mfu 38.60%
iter 1070: loss 0.7649, time 9.47ms, mfu 38.70%
iter 1080: loss 0.7366, time 9.38ms, mfu 38.82%
iter 1090: loss 0.7802, time 9.31ms, mfu 38.96%
iter 1100: loss 0.7536, time 9.29ms, mfu 39.10%
iter 1110: loss 0.7723, time 9.32ms, mfu 39.21%
iter 1120: loss 0.7330, time 9.41ms, mfu 39.27%
iter 1130: loss 0.8055, time 9.24ms, mfu 39.40%
iter 1140: loss 0.7194, time 9.51ms, mfu 39.40%
iter 1150: loss 0.7183, time 9.38ms, mfu 39.45%
iter 1160: loss 0.7529, time 9.44ms, mfu 39.47%
iter 1170: loss 0.7365, time 9.32ms, mfu 39.55%
iter 1180: loss 0.6997, time 9.43ms, mfu 39.56%
iter 1190: loss 0.7305, time 9.48ms, mfu 39.56%
iter 1200: loss 0.7127, time 9.37ms, mfu 39.60%
iter 1210: loss 0.7452, time 7.15ms, mfu 40.88%
iter 1220: loss 0.7263, time 9.32ms, mfu 40.81%
iter 1230: loss 0.7506, time 9.39ms, mfu 40.72%
iter 1240: loss 0.7435, time 9.42ms, mfu 40.62%
step 1250: train loss 0.7325, val loss 0.7305
saving checkpoint to out-experiment2_width-n_embd_384
iter 1250: loss 0.7222, time 2508.72ms, mfu 36.57%
iter 1260: loss 0.7647, time 8.00ms, mfu 37.60%
iter 1270: loss 0.7260, time 9.35ms, mfu 37.85%
iter 1280: loss 0.7310, time 9.36ms, mfu 38.06%
iter 1290: loss 0.7003, time 9.30ms, mfu 38.29%
iter 1300: loss 0.7805, time 9.34ms, mfu 38.47%
iter 1310: loss 0.7104, time 9.52ms, mfu 38.56%
iter 1320: loss 0.7012, time 9.51ms, mfu 38.64%
iter 1330: loss 0.7417, time 9.50ms, mfu 38.72%
iter 1340: loss 0.6969, time 9.40ms, mfu 38.84%
iter 1350: loss 0.7322, time 9.46ms, mfu 38.91%
iter 1360: loss 0.6939, time 9.39ms, mfu 39.01%
iter 1370: loss 0.7330, time 9.43ms, mfu 39.08%
iter 1380: loss 0.7563, time 9.44ms, mfu 39.14%
iter 1390: loss 0.6608, time 9.36ms, mfu 39.23%
iter 1400: loss 0.7142, time 9.32ms, mfu 39.33%
iter 1410: loss 0.7146, time 9.38ms, mfu 39.39%
iter 1420: loss 0.7140, time 9.36ms, mfu 39.45%
iter 1430: loss 0.6998, time 9.39ms, mfu 39.49%
iter 1440: loss 0.7003, time 9.43ms, mfu 39.52%
iter 1450: loss 0.7125, time 9.42ms, mfu 39.54%
iter 1460: loss 0.6965, time 9.43ms, mfu 39.56%
iter 1470: loss 0.6721, time 9.47ms, mfu 39.56%
iter 1480: loss 0.7054, time 9.45ms, mfu 39.57%
iter 1490: loss 0.7036, time 9.46ms, mfu 39.57%
step 1500: train loss 0.7066, val loss 0.7064
saving checkpoint to out-experiment2_width-n_embd_384
iter 1500: loss 0.6836, time 2493.42ms, mfu 35.63%
iter 1510: loss 0.7238, time 6.98ms, mfu 37.43%
iter 1520: loss 0.6922, time 9.39ms, mfu 37.68%
iter 1530: loss 0.6980, time 9.19ms, mfu 37.99%
iter 1540: loss 0.6637, time 9.31ms, mfu 38.21%
iter 1550: loss 0.6889, time 9.44ms, mfu 38.36%
iter 1560: loss 0.7095, time 9.52ms, mfu 38.46%
iter 1570: loss 0.7138, time 9.41ms, mfu 38.59%
iter 1580: loss 0.6759, time 9.34ms, mfu 38.75%
iter 1590: loss 0.7391, time 9.42ms, mfu 38.85%
iter 1600: loss 0.6929, time 9.44ms, mfu 38.93%
iter 1610: loss 0.6779, time 9.52ms, mfu 38.97%
iter 1620: loss 0.7330, time 9.47ms, mfu 39.03%
iter 1630: loss 0.6990, time 9.42ms, mfu 39.10%
iter 1640: loss 0.6980, time 9.41ms, mfu 39.17%
iter 1650: loss 0.6802, time 9.55ms, mfu 39.18%
iter 1660: loss 0.6817, time 9.35ms, mfu 39.27%
iter 1670: loss 0.6428, time 9.42ms, mfu 39.32%
iter 1680: loss 0.6774, time 9.33ms, mfu 39.40%
iter 1690: loss 0.7122, time 9.43ms, mfu 39.43%
iter 1700: loss 0.6771, time 9.45ms, mfu 39.45%
iter 1710: loss 0.6657, time 9.54ms, mfu 39.43%
iter 1720: loss 0.6611, time 9.44ms, mfu 39.46%
iter 1730: loss 0.6597, time 9.43ms, mfu 39.48%
iter 1740: loss 0.6984, time 9.51ms, mfu 39.47%
step 1750: train loss 0.6833, val loss 0.6834
saving checkpoint to out-experiment2_width-n_embd_384
iter 1750: loss 0.6735, time 2540.74ms, mfu 35.54%
iter 1760: loss 0.6670, time 6.45ms, mfu 37.79%
iter 1770: loss 0.6833, time 9.45ms, mfu 37.98%
iter 1780: loss 0.6881, time 9.28ms, mfu 38.21%
iter 1790: loss 0.6892, time 9.53ms, mfu 38.33%
iter 1800: loss 0.6744, time 9.21ms, mfu 38.56%
iter 1810: loss 0.6817, time 9.41ms, mfu 38.68%
iter 1820: loss 0.6811, time 9.52ms, mfu 38.75%
iter 1830: loss 0.6571, time 9.45ms, mfu 38.84%
iter 1840: loss 0.6506, time 9.32ms, mfu 38.98%
iter 1850: loss 0.6465, time 9.34ms, mfu 39.09%
iter 1860: loss 0.6874, time 9.55ms, mfu 39.10%
iter 1870: loss 0.6779, time 9.32ms, mfu 39.21%
iter 1880: loss 0.6562, time 9.44ms, mfu 39.26%
iter 1890: loss 0.6816, time 9.55ms, mfu 39.25%
iter 1900: loss 0.7023, time 9.36ms, mfu 39.33%
iter 1910: loss 0.6809, time 9.43ms, mfu 39.37%
iter 1920: loss 0.6696, time 8.68ms, mfu 39.75%
iter 1930: loss 0.6263, time 9.46ms, mfu 39.74%
iter 1940: loss 0.7076, time 9.47ms, mfu 39.72%
iter 1950: loss 0.6789, time 9.55ms, mfu 39.67%
iter 1960: loss 0.6993, time 9.45ms, mfu 39.67%
iter 1970: loss 0.6946, time 9.29ms, mfu 39.73%
iter 1980: loss 0.6627, time 9.54ms, mfu 39.69%
iter 1990: loss 0.6719, time 9.54ms, mfu 39.64%
step 2000: train loss 0.6621, val loss 0.6641
saving checkpoint to out-experiment2_width-n_embd_384
iter 2000: loss 0.6529, time 2547.89ms, mfu 35.69%
iter 2010: loss 0.6613, time 5.60ms, mfu 38.82%
iter 2020: loss 0.6524, time 9.34ms, mfu 38.94%
iter 2030: loss 0.6845, time 9.17ms, mfu 39.13%
iter 2040: loss 0.6655, time 9.29ms, mfu 39.25%
iter 2050: loss 0.6597, time 9.34ms, mfu 39.34%
iter 2060: loss 0.6362, time 9.34ms, mfu 39.42%
iter 2070: loss 0.6269, time 9.54ms, mfu 39.40%
iter 2080: loss 0.6763, time 9.56ms, mfu 39.38%
iter 2090: loss 0.6903, time 9.56ms, mfu 39.36%
iter 2100: loss 0.6544, time 9.55ms, mfu 39.35%
iter 2110: loss 0.6620, time 9.39ms, mfu 39.40%
iter 2120: loss 0.6519, time 9.41ms, mfu 39.44%
iter 2130: loss 0.6219, time 9.58ms, mfu 39.41%
iter 2140: loss 0.6767, time 9.37ms, mfu 39.46%
iter 2150: loss 0.6630, time 9.56ms, mfu 39.44%
iter 2160: loss 0.6804, time 9.45ms, mfu 39.46%
iter 2170: loss 0.6497, time 9.60ms, mfu 39.41%
iter 2180: loss 0.6872, time 9.51ms, mfu 39.41%
iter 2190: loss 0.6457, time 9.59ms, mfu 39.38%
iter 2200: loss 0.6300, time 9.44ms, mfu 39.41%
iter 2210: loss 0.6881, time 9.44ms, mfu 39.44%
iter 2220: loss 0.6808, time 9.57ms, mfu 39.41%
iter 2230: loss 0.6421, time 9.42ms, mfu 39.44%
iter 2240: loss 0.6347, time 9.51ms, mfu 39.44%
step 2250: train loss 0.6454, val loss 0.6454
saving checkpoint to out-experiment2_width-n_embd_384
iter 2250: loss 0.6324, time 2547.41ms, mfu 35.51%
iter 2260: loss 0.6791, time 8.36ms, mfu 36.44%
iter 2270: loss 0.6873, time 7.99ms, mfu 37.48%
iter 2280: loss 0.6672, time 9.30ms, mfu 37.76%
iter 2290: loss 0.6397, time 9.40ms, mfu 37.97%
iter 2300: loss 0.6779, time 9.43ms, mfu 38.15%
iter 2310: loss 0.6509, time 9.48ms, mfu 38.28%
iter 2320: loss 0.6467, time 9.42ms, mfu 38.43%
iter 2330: loss 0.6410, time 9.38ms, mfu 38.59%
iter 2340: loss 0.6754, time 9.31ms, mfu 38.75%
iter 2350: loss 0.6549, time 9.38ms, mfu 38.87%
iter 2360: loss 0.6083, time 9.55ms, mfu 38.91%
iter 2370: loss 0.6297, time 9.44ms, mfu 38.99%
iter 2380: loss 0.6335, time 9.43ms, mfu 39.06%
iter 2390: loss 0.6366, time 9.62ms, mfu 39.05%
iter 2400: loss 0.6681, time 9.31ms, mfu 39.17%
iter 2410: loss 0.6693, time 9.58ms, mfu 39.16%
iter 2420: loss 0.6425, time 9.43ms, mfu 39.22%
iter 2430: loss 0.6429, time 9.55ms, mfu 39.22%
iter 2440: loss 0.6040, time 9.58ms, mfu 39.21%
iter 2450: loss 0.6259, time 9.63ms, mfu 39.18%
iter 2460: loss 0.6562, time 9.57ms, mfu 39.17%
iter 2470: loss 0.6116, time 9.43ms, mfu 39.23%
iter 2480: loss 0.6415, time 9.49ms, mfu 39.26%
iter 2490: loss 0.6610, time 9.33ms, mfu 39.35%
step 2500: train loss 0.6311, val loss 0.6319
saving checkpoint to out-experiment2_width-n_embd_384
iter 2500: loss 0.6330, time 2540.70ms, mfu 35.43%
iter 2510: loss 0.6483, time 8.59ms, mfu 36.24%
iter 2520: loss 0.6555, time 9.24ms, mfu 36.67%
iter 2530: loss 0.6466, time 9.36ms, mfu 37.01%
iter 2540: loss 0.6411, time 9.62ms, mfu 37.20%
iter 2550: loss 0.6572, time 9.33ms, mfu 37.49%
iter 2560: loss 0.6522, time 9.41ms, mfu 37.73%
iter 2570: loss 0.6160, time 9.33ms, mfu 37.97%
iter 2580: loss 0.6527, time 9.57ms, mfu 38.09%
iter 2590: loss 0.6016, time 9.49ms, mfu 38.22%
iter 2600: loss 0.6548, time 9.40ms, mfu 38.39%
iter 2610: loss 0.6336, time 9.45ms, mfu 38.51%
iter 2620: loss 0.6533, time 9.49ms, mfu 38.61%
iter 2630: loss 0.6184, time 9.40ms, mfu 38.73%
iter 2640: loss 0.6071, time 8.08ms, mfu 39.50%
iter 2650: loss 0.6598, time 9.50ms, mfu 39.49%
iter 2660: loss 0.5948, time 9.38ms, mfu 39.54%
iter 2670: loss 0.6400, time 9.48ms, mfu 39.53%
iter 2680: loss 0.6251, time 9.35ms, mfu 39.59%
iter 2690: loss 0.6461, time 9.44ms, mfu 39.60%
iter 2700: loss 0.6215, time 9.53ms, mfu 39.57%
iter 2710: loss 0.6327, time 9.38ms, mfu 39.61%
iter 2720: loss 0.6037, time 9.36ms, mfu 39.65%
iter 2730: loss 0.5966, time 9.40ms, mfu 39.67%
iter 2740: loss 0.6029, time 9.59ms, mfu 39.61%
step 2750: train loss 0.6180, val loss 0.6190
saving checkpoint to out-experiment2_width-n_embd_384
iter 2750: loss 0.6523, time 2577.81ms, mfu 35.66%
iter 2760: loss 0.5929, time 7.38ms, mfu 37.17%
iter 2770: loss 0.6029, time 9.46ms, mfu 37.41%
iter 2780: loss 0.6261, time 9.32ms, mfu 37.69%
iter 2790: loss 0.6089, time 9.50ms, mfu 37.87%
iter 2800: loss 0.5993, time 9.42ms, mfu 38.06%
iter 2810: loss 0.6293, time 9.30ms, mfu 38.28%
iter 2820: loss 0.6263, time 9.47ms, mfu 38.40%
iter 2830: loss 0.6126, time 9.60ms, mfu 38.47%
iter 2840: loss 0.5923, time 9.45ms, mfu 38.58%
iter 2850: loss 0.5996, time 9.48ms, mfu 38.67%
iter 2860: loss 0.6192, time 9.34ms, mfu 38.82%
iter 2870: loss 0.6319, time 9.55ms, mfu 38.86%
iter 2880: loss 0.5993, time 9.48ms, mfu 38.93%
iter 2890: loss 0.5930, time 9.42ms, mfu 39.01%
iter 2900: loss 0.5983, time 9.46ms, mfu 39.07%
iter 2910: loss 0.6025, time 9.64ms, mfu 39.05%
iter 2920: loss 0.6114, time 9.50ms, mfu 39.08%
iter 2930: loss 0.6275, time 9.48ms, mfu 39.13%
iter 2940: loss 0.5772, time 9.46ms, mfu 39.17%
iter 2950: loss 0.6155, time 9.47ms, mfu 39.21%
iter 2960: loss 0.6113, time 9.52ms, mfu 39.23%
iter 2970: loss 0.6007, time 9.51ms, mfu 39.24%
iter 2980: loss 0.6088, time 9.37ms, mfu 39.32%
iter 2990: loss 0.6103, time 9.53ms, mfu 39.32%
step 3000: train loss 0.6079, val loss 0.6088
saving checkpoint to out-experiment2_width-n_embd_384
iter 3000: loss 0.5787, time 2563.36ms, mfu 35.40%
iter 3010: loss 0.6263, time 8.64ms, mfu 36.20%
iter 3020: loss 0.6186, time 9.47ms, mfu 36.53%
iter 3030: loss 0.6110, time 9.22ms, mfu 36.94%
iter 3040: loss 0.6054, time 9.47ms, mfu 37.21%
iter 3050: loss 0.5840, time 9.48ms, mfu 37.44%
iter 3060: loss 0.6288, time 9.52ms, mfu 37.63%
iter 3070: loss 0.6011, time 9.56ms, mfu 37.78%
iter 3080: loss 0.5940, time 9.45ms, mfu 37.97%
iter 3090: loss 0.6438, time 9.36ms, mfu 38.17%
iter 3100: loss 0.5991, time 9.40ms, mfu 38.34%
iter 3110: loss 0.6244, time 9.65ms, mfu 38.39%
iter 3120: loss 0.5909, time 9.61ms, mfu 38.45%
iter 3130: loss 0.5852, time 9.54ms, mfu 38.53%
iter 3140: loss 0.6046, time 9.34ms, mfu 38.69%
iter 3150: loss 0.6069, time 9.46ms, mfu 38.78%
iter 3160: loss 0.5873, time 9.43ms, mfu 38.87%
iter 3170: loss 0.6056, time 9.55ms, mfu 38.91%
iter 3180: loss 0.5895, time 9.60ms, mfu 38.92%
iter 3190: loss 0.5786, time 9.50ms, mfu 38.97%
iter 3200: loss 0.5669, time 9.48ms, mfu 39.02%
iter 3210: loss 0.6044, time 9.65ms, mfu 39.01%
iter 3220: loss 0.5877, time 9.52ms, mfu 39.04%
iter 3230: loss 0.5600, time 9.48ms, mfu 39.09%
iter 3240: loss 0.6071, time 9.43ms, mfu 39.15%
step 3250: train loss 0.5983, val loss 0.5979
saving checkpoint to out-experiment2_width-n_embd_384
iter 3250: loss 0.5927, time 2529.74ms, mfu 35.25%
iter 3260: loss 0.5954, time 8.54ms, mfu 36.11%
iter 3270: loss 0.5926, time 9.45ms, mfu 36.47%
iter 3280: loss 0.5954, time 9.30ms, mfu 36.85%
iter 3290: loss 0.5920, time 9.42ms, mfu 37.14%
iter 3300: loss 0.5830, time 9.46ms, mfu 37.38%
iter 3310: loss 0.5977, time 9.36ms, mfu 37.65%
iter 3320: loss 0.5796, time 9.49ms, mfu 37.83%
iter 3330: loss 0.6141, time 9.49ms, mfu 38.00%
iter 3340: loss 0.5845, time 9.63ms, mfu 38.08%
iter 3350: loss 0.6086, time 9.49ms, mfu 38.22%
iter 3360: loss 0.5912, time 9.49ms, mfu 38.35%
iter 3370: loss 0.5998, time 9.49ms, mfu 38.46%
iter 3380: loss 0.5743, time 9.50ms, mfu 38.56%
iter 3390: loss 0.5851, time 9.48ms, mfu 38.65%
iter 3400: loss 0.5876, time 9.49ms, mfu 38.74%
iter 3410: loss 0.5891, time 9.52ms, mfu 38.80%
iter 3420: loss 0.5915, time 9.41ms, mfu 38.90%
iter 3430: loss 0.6023, time 9.46ms, mfu 38.97%
iter 3440: loss 0.5720, time 9.43ms, mfu 39.04%
iter 3450: loss 0.5970, time 9.59ms, mfu 39.05%
iter 3460: loss 0.6132, time 9.52ms, mfu 39.08%
iter 3470: loss 0.5618, time 9.49ms, mfu 39.12%
iter 3480: loss 0.6049, time 9.57ms, mfu 39.12%
iter 3490: loss 0.5812, time 9.54ms, mfu 39.14%
step 3500: train loss 0.5870, val loss 0.5890
saving checkpoint to out-experiment2_width-n_embd_384
iter 3500: loss 0.6050, time 2478.75ms, mfu 35.24%
iter 3510: loss 0.6008, time 8.58ms, mfu 36.08%
iter 3520: loss 0.6039, time 9.37ms, mfu 36.47%
iter 3530: loss 0.6038, time 9.36ms, mfu 36.82%
iter 3540: loss 0.5641, time 9.42ms, mfu 37.12%
iter 3550: loss 0.6062, time 9.39ms, mfu 37.39%
iter 3560: loss 0.6205, time 9.50ms, mfu 37.60%
iter 3570: loss 0.5753, time 9.54ms, mfu 37.77%
iter 3580: loss 0.5773, time 9.56ms, mfu 37.91%
iter 3590: loss 0.5859, time 9.57ms, mfu 38.03%
iter 3600: loss 0.5699, time 9.50ms, mfu 38.17%
iter 3610: loss 0.5624, time 9.54ms, mfu 38.28%
iter 3620: loss 0.5724, time 9.49ms, mfu 38.40%
iter 3630: loss 0.5995, time 9.46ms, mfu 38.52%
iter 3640: loss 0.5857, time 9.59ms, mfu 38.58%
iter 3650: loss 0.5993, time 9.50ms, mfu 38.66%
iter 3660: loss 0.5863, time 9.51ms, mfu 38.73%
iter 3670: loss 0.5711, time 9.51ms, mfu 38.80%
iter 3680: loss 0.5644, time 9.52ms, mfu 38.85%
iter 3690: loss 0.5786, time 9.44ms, mfu 38.94%
iter 3700: loss 0.5523, time 9.47ms, mfu 39.00%
iter 3710: loss 0.5765, time 9.52ms, mfu 39.03%
iter 3720: loss 0.5757, time 9.51ms, mfu 39.07%
iter 3730: loss 0.6078, time 9.55ms, mfu 39.08%
iter 3740: loss 0.5915, time 9.48ms, mfu 39.13%
step 3750: train loss 0.5814, val loss 0.5800
saving checkpoint to out-experiment2_width-n_embd_384
iter 3750: loss 0.6164, time 2492.09ms, mfu 35.23%
iter 3760: loss 0.6185, time 6.40ms, mfu 37.56%
iter 3770: loss 0.5830, time 9.41ms, mfu 37.79%
iter 3780: loss 0.5916, time 9.31ms, mfu 38.03%
iter 3790: loss 0.5900, time 9.43ms, mfu 38.20%
iter 3800: loss 0.5954, time 9.41ms, mfu 38.36%
iter 3810: loss 0.5594, time 9.49ms, mfu 38.47%
iter 3820: loss 0.5728, time 9.48ms, mfu 38.58%
iter 3830: loss 0.6046, time 9.49ms, mfu 38.66%
iter 3840: loss 0.5794, time 9.40ms, mfu 38.78%
iter 3850: loss 0.5812, time 9.42ms, mfu 38.88%
iter 3860: loss 0.5668, time 9.50ms, mfu 38.94%
iter 3870: loss 0.5541, time 9.53ms, mfu 38.98%
iter 3880: loss 0.5574, time 9.44ms, mfu 39.05%
iter 3890: loss 0.5818, time 9.47ms, mfu 39.10%
iter 3900: loss 0.5596, time 9.54ms, mfu 39.11%
iter 3910: loss 0.5765, time 9.54ms, mfu 39.13%
iter 3920: loss 0.5334, time 9.53ms, mfu 39.15%
iter 3930: loss 0.5840, time 9.50ms, mfu 39.18%
iter 3940: loss 0.5878, time 9.48ms, mfu 39.21%
iter 3950: loss 0.5857, time 9.54ms, mfu 39.21%
iter 3960: loss 0.5828, time 9.50ms, mfu 39.24%
iter 3970: loss 0.6020, time 9.52ms, mfu 39.25%
iter 3980: loss 0.5628, time 9.58ms, mfu 39.24%
iter 3990: loss 0.6055, time 9.40ms, mfu 39.30%
step 4000: train loss 0.5722, val loss 0.5714
saving checkpoint to out-experiment2_width-n_embd_384
iter 4000: loss 0.5751, time 2558.37ms, mfu 35.38%
iter 4010: loss 0.5438, time 8.56ms, mfu 36.22%
iter 4020: loss 0.5728, time 9.57ms, mfu 36.51%
iter 4030: loss 0.5535, time 9.38ms, mfu 36.85%
iter 4040: loss 0.5944, time 9.51ms, mfu 37.11%
iter 4050: loss 0.5764, time 9.48ms, mfu 37.35%
iter 4060: loss 0.5823, time 9.62ms, mfu 37.51%
iter 4070: loss 0.5555, time 9.50ms, mfu 37.70%
iter 4080: loss 0.5719, time 9.58ms, mfu 37.84%
iter 4090: loss 0.5702, time 9.48ms, mfu 38.01%
iter 4100: loss 0.5978, time 9.48ms, mfu 38.16%
iter 4110: loss 0.5565, time 9.54ms, mfu 38.27%
iter 4120: loss 0.5790, time 9.54ms, mfu 38.37%
iter 4130: loss 0.5853, time 9.56ms, mfu 38.45%
iter 4140: loss 0.5930, time 9.56ms, mfu 38.52%
iter 4150: loss 0.5678, time 9.63ms, mfu 38.56%
iter 4160: loss 0.5778, time 9.50ms, mfu 38.65%
iter 4170: loss 0.5707, time 9.51ms, mfu 38.72%
iter 4180: loss 0.5755, time 9.36ms, mfu 38.85%
iter 4190: loss 0.5886, time 9.50ms, mfu 38.91%
iter 4200: loss 0.5235, time 9.51ms, mfu 38.96%
iter 4210: loss 0.5793, time 9.52ms, mfu 39.00%
iter 4220: loss 0.5792, time 9.51ms, mfu 39.04%
iter 4230: loss 0.5555, time 9.57ms, mfu 39.05%
iter 4240: loss 0.5530, time 9.48ms, mfu 39.09%
step 4250: train loss 0.5667, val loss 0.5643
saving checkpoint to out-experiment2_width-n_embd_384
iter 4250: loss 0.6239, time 2538.67ms, mfu 35.20%
iter 4260: loss 0.5507, time 5.10ms, mfu 39.03%
iter 4270: loss 0.5560, time 9.48ms, mfu 39.08%
iter 4280: loss 0.5790, time 9.38ms, mfu 39.16%
iter 4290: loss 0.5504, time 9.50ms, mfu 39.19%
iter 4300: loss 0.5506, time 9.60ms, mfu 39.17%
iter 4310: loss 0.5580, time 9.45ms, mfu 39.22%
iter 4320: loss 0.5762, time 9.50ms, mfu 39.24%
iter 4330: loss 0.6091, time 9.46ms, mfu 39.28%
iter 4340: loss 0.5744, time 9.47ms, mfu 39.30%
iter 4350: loss 0.5577, time 9.60ms, mfu 39.28%
iter 4360: loss 0.5551, time 9.52ms, mfu 39.29%
iter 4370: loss 0.5739, time 9.50ms, mfu 39.30%
iter 4380: loss 0.5508, time 9.44ms, mfu 39.34%
iter 4390: loss 0.5368, time 9.47ms, mfu 39.36%
iter 4400: loss 0.5664, time 9.53ms, mfu 39.36%
iter 4410: loss 0.5986, time 9.50ms, mfu 39.36%
iter 4420: loss 0.5788, time 9.54ms, mfu 39.35%
iter 4430: loss 0.5539, time 9.49ms, mfu 39.37%
iter 4440: loss 0.5748, time 9.50ms, mfu 39.37%
iter 4450: loss 0.5599, time 9.53ms, mfu 39.37%
iter 4460: loss 0.5527, time 9.53ms, mfu 39.36%
iter 4470: loss 0.5730, time 9.43ms, mfu 39.39%
iter 4480: loss 0.5527, time 9.59ms, mfu 39.36%
iter 4490: loss 0.5655, time 9.54ms, mfu 39.35%
step 4500: train loss 0.5633, val loss 0.5628
saving checkpoint to out-experiment2_width-n_embd_384
iter 4500: loss 0.5241, time 2567.13ms, mfu 35.43%
iter 4510: loss 0.5625, time 8.58ms, mfu 36.26%
iter 4520: loss 0.5844, time 9.39ms, mfu 36.62%
iter 4530: loss 0.5329, time 9.51ms, mfu 36.90%
iter 4540: loss 0.5487, time 9.43ms, mfu 37.18%
iter 4550: loss 0.5654, time 9.48ms, mfu 37.41%
iter 4560: loss 0.5497, time 9.51ms, mfu 37.61%
iter 4570: loss 0.5588, time 9.50ms, mfu 37.79%
iter 4580: loss 0.5570, time 9.56ms, mfu 37.93%
iter 4590: loss 0.5607, time 9.52ms, mfu 38.08%
iter 4600: loss 0.5543, time 9.54ms, mfu 38.19%
iter 4610: loss 0.5705, time 9.53ms, mfu 38.30%
iter 4620: loss 0.5737, time 9.67ms, mfu 38.35%
iter 4630: loss 0.5680, time 9.57ms, mfu 38.43%
iter 4640: loss 0.5691, time 9.50ms, mfu 38.53%
iter 4650: loss 0.5376, time 9.50ms, mfu 38.62%
iter 4660: loss 0.5586, time 9.48ms, mfu 38.71%
iter 4670: loss 0.5624, time 9.56ms, mfu 38.76%
iter 4680: loss 0.5631, time 9.53ms, mfu 38.81%
iter 4690: loss 0.5402, time 9.54ms, mfu 38.86%
iter 4700: loss 0.5763, time 9.53ms, mfu 38.91%
iter 4710: loss 0.5875, time 9.43ms, mfu 38.99%
iter 4720: loss 0.5828, time 9.56ms, mfu 39.01%
iter 4730: loss 0.5343, time 9.48ms, mfu 39.06%
iter 4740: loss 0.5634, time 9.52ms, mfu 39.09%
step 4750: train loss 0.5589, val loss 0.5598
saving checkpoint to out-experiment2_width-n_embd_384
iter 4750: loss 0.5504, time 2538.49ms, mfu 35.19%
iter 4760: loss 0.5710, time 6.58ms, mfu 37.36%
iter 4770: loss 0.5774, time 9.42ms, mfu 37.60%
iter 4780: loss 0.5607, time 9.34ms, mfu 37.86%
iter 4790: loss 0.5871, time 9.39ms, mfu 38.06%
iter 4800: loss 0.5260, time 9.52ms, mfu 38.19%
iter 4810: loss 0.5454, time 9.51ms, mfu 38.31%
iter 4820: loss 0.5637, time 9.49ms, mfu 38.43%
iter 4830: loss 0.5363, time 9.53ms, mfu 38.51%
iter 4840: loss 0.5852, time 9.55ms, mfu 38.58%
iter 4850: loss 0.5899, time 9.54ms, mfu 38.65%
iter 4860: loss 0.5795, time 9.48ms, mfu 38.74%
iter 4870: loss 0.5717, time 9.58ms, mfu 38.78%
iter 4880: loss 0.5700, time 9.56ms, mfu 38.82%
iter 4890: loss 0.5805, time 9.53ms, mfu 38.86%
iter 4900: loss 0.5591, time 9.58ms, mfu 38.89%
iter 4910: loss 0.5719, time 9.54ms, mfu 38.93%
iter 4920: loss 0.5898, time 9.57ms, mfu 38.95%
iter 4930: loss 0.5439, time 9.52ms, mfu 38.99%
iter 4940: loss 0.5546, time 9.55ms, mfu 39.01%
iter 4950: loss 0.5658, time 9.54ms, mfu 39.04%
iter 4960: loss 0.5329, time 9.57ms, mfu 39.05%
iter 4970: loss 0.5323, time 9.52ms, mfu 39.08%
iter 4980: loss 0.5495, time 9.55ms, mfu 39.09%
iter 4990: loss 0.5470, time 9.50ms, mfu 39.13%
step 5000: train loss 0.5548, val loss 0.5557
saving checkpoint to out-experiment2_width-n_embd_384
iter 5000: loss 0.5823, time 2503.47ms, mfu 35.23%


STDERR:
/data/lst141/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
