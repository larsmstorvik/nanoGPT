Overriding config with config/train_tinystories.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-experiment2_width-n_embd_192'
eval_interval = 250
eval_iters = 200
log_interval = 10

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False
wandb_project = 'tinystories'
wandb_run_name = 'experiment2_width_n_embd_192'

dataset = 'tinystories'
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256

# baby GPT model :)
n_layer = 6
n_head = 8
n_embd = 192
dropout = 0.0

learning_rate = 0.001
max_iters = 5000
lr_decay_iters = 5000
min_lr = 0.0001
beta2 = 0.99

warmup_iters = 100

device = 'cuda:1'

tokens per iteration will be: 16,384
found vocab_size = 228 (inside data/tinystories/meta.pkl)
Initializing a new model from scratch
number of parameters: 2.70M
num decayed parameter tensors: 26, with 2,747,136 parameters
num non-decayed parameter tensors: 13, with 2,496 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 5.4563, val loss 5.4565
iter 0: loss 5.4536, time 10752.14ms, mfu -100.00%
iter 10: loss 4.4081, time 4.71ms, mfu 21.99%
iter 20: loss 3.8762, time 4.83ms, mfu 21.94%
iter 30: loss 3.3484, time 4.72ms, mfu 21.94%
iter 40: loss 2.9102, time 4.60ms, mfu 22.00%
iter 50: loss 2.6079, time 4.66ms, mfu 22.03%
iter 60: loss 2.5168, time 4.71ms, mfu 22.03%
iter 70: loss 2.3991, time 4.80ms, mfu 21.98%
iter 80: loss 2.3714, time 4.81ms, mfu 21.94%
iter 90: loss 2.3178, time 4.79ms, mfu 21.91%
iter 100: loss 2.3102, time 4.79ms, mfu 21.88%
iter 110: loss 2.2937, time 4.59ms, mfu 21.95%
iter 120: loss 2.2537, time 4.72ms, mfu 21.95%
iter 130: loss 2.2176, time 4.59ms, mfu 22.02%
iter 140: loss 2.1704, time 4.57ms, mfu 22.09%
iter 150: loss 2.1957, time 4.65ms, mfu 22.11%
iter 160: loss 2.1522, time 4.69ms, mfu 22.10%
iter 170: loss 2.1072, time 4.33ms, mfu 22.29%
iter 180: loss 2.0714, time 4.59ms, mfu 22.32%
iter 190: loss 2.0589, time 4.57ms, mfu 22.36%
iter 200: loss 2.0083, time 4.50ms, mfu 22.42%
iter 210: loss 1.9861, time 4.31ms, mfu 22.58%
iter 220: loss 1.9437, time 4.69ms, mfu 22.54%
iter 230: loss 1.9268, time 4.57ms, mfu 22.55%
iter 240: loss 1.8628, time 4.70ms, mfu 22.50%
step 250: train loss 1.8349, val loss 1.8332
saving checkpoint to out-experiment2_width-n_embd_192
iter 250: loss 1.8609, time 1260.51ms, mfu 20.26%
iter 260: loss 1.7815, time 4.64ms, mfu 20.47%
iter 270: loss 1.7520, time 4.68ms, mfu 20.63%
iter 280: loss 1.7234, time 4.72ms, mfu 20.77%
iter 290: loss 1.6729, time 4.59ms, mfu 20.95%
iter 300: loss 1.6221, time 4.85ms, mfu 20.99%
iter 310: loss 1.6253, time 4.56ms, mfu 21.17%
iter 320: loss 1.5957, time 4.81ms, mfu 21.20%
iter 330: loss 1.5448, time 4.64ms, mfu 21.32%
iter 340: loss 1.4976, time 4.66ms, mfu 21.41%
iter 350: loss 1.4863, time 4.68ms, mfu 21.48%
iter 360: loss 1.4546, time 4.37ms, mfu 21.71%
iter 370: loss 1.4495, time 4.73ms, mfu 21.73%
iter 380: loss 1.4444, time 4.71ms, mfu 21.76%
iter 390: loss 1.3420, time 4.64ms, mfu 21.82%
iter 400: loss 1.3731, time 4.67ms, mfu 21.85%
iter 410: loss 1.3450, time 4.60ms, mfu 21.92%
iter 420: loss 1.3465, time 4.75ms, mfu 21.92%
iter 430: loss 1.3481, time 4.69ms, mfu 21.93%
iter 440: loss 1.3288, time 4.69ms, mfu 21.95%
iter 450: loss 1.2939, time 4.72ms, mfu 21.95%
iter 460: loss 1.2979, time 4.76ms, mfu 21.93%
iter 470: loss 1.2684, time 4.79ms, mfu 21.90%
iter 480: loss 1.3021, time 4.76ms, mfu 21.89%
iter 490: loss 1.2259, time 5.33ms, mfu 21.65%
step 500: train loss 1.2217, val loss 1.2218
saving checkpoint to out-experiment2_width-n_embd_192
iter 500: loss 1.2488, time 1471.22ms, mfu 19.49%
iter 510: loss 1.1970, time 4.61ms, mfu 19.79%
iter 520: loss 1.1908, time 4.65ms, mfu 20.04%
iter 530: loss 1.1616, time 4.81ms, mfu 20.19%
iter 540: loss 1.2002, time 4.64ms, mfu 20.40%
iter 550: loss 1.1849, time 4.80ms, mfu 20.52%
iter 560: loss 1.1615, time 4.72ms, mfu 20.67%
iter 570: loss 1.1466, time 4.75ms, mfu 20.78%
iter 580: loss 1.1102, time 4.82ms, mfu 20.85%
iter 590: loss 1.1497, time 4.76ms, mfu 20.95%
iter 600: loss 1.1368, time 4.82ms, mfu 21.00%
iter 610: loss 1.0609, time 4.78ms, mfu 21.07%
iter 620: loss 1.0414, time 4.65ms, mfu 21.19%
iter 630: loss 1.0905, time 4.84ms, mfu 21.21%
iter 640: loss 1.0441, time 4.74ms, mfu 21.28%
iter 650: loss 1.0674, time 4.69ms, mfu 21.36%
iter 660: loss 1.0867, time 4.70ms, mfu 21.43%
iter 670: loss 1.0441, time 4.61ms, mfu 21.54%
iter 680: loss 1.0334, time 4.63ms, mfu 21.62%
iter 690: loss 1.0656, time 4.69ms, mfu 21.67%
iter 700: loss 1.0728, time 4.31ms, mfu 21.91%
iter 710: loss 1.0469, time 4.35ms, mfu 22.10%
iter 720: loss 1.0477, time 4.42ms, mfu 22.24%
iter 730: loss 1.0160, time 4.58ms, mfu 22.27%
iter 740: loss 1.0336, time 4.60ms, mfu 22.30%
step 750: train loss 1.0208, val loss 1.0223
saving checkpoint to out-experiment2_width-n_embd_192
iter 750: loss 1.0312, time 1401.68ms, mfu 20.08%
iter 760: loss 1.0259, time 4.78ms, mfu 20.24%
iter 770: loss 0.9774, time 4.76ms, mfu 20.39%
iter 780: loss 1.0159, time 4.87ms, mfu 20.48%
iter 790: loss 1.0333, time 4.86ms, mfu 20.57%
iter 800: loss 0.9781, time 4.83ms, mfu 20.66%
iter 810: loss 0.9745, time 4.72ms, mfu 20.79%
iter 820: loss 0.9781, time 4.90ms, mfu 20.82%
iter 830: loss 1.0061, time 4.78ms, mfu 20.91%
iter 840: loss 0.9725, time 4.72ms, mfu 21.02%
iter 850: loss 0.9748, time 4.87ms, mfu 21.05%
iter 860: loss 0.9972, time 4.66ms, mfu 21.17%
iter 870: loss 1.0039, time 4.78ms, mfu 21.22%
iter 880: loss 0.9507, time 4.74ms, mfu 21.28%
iter 890: loss 0.9287, time 4.56ms, mfu 21.43%
iter 900: loss 0.9833, time 4.37ms, mfu 21.66%
iter 910: loss 0.9580, time 4.61ms, mfu 21.74%
iter 920: loss 0.9429, time 4.60ms, mfu 21.82%
iter 930: loss 1.0054, time 4.37ms, mfu 22.01%
iter 940: loss 0.9670, time 4.62ms, mfu 22.05%
iter 950: loss 0.9053, time 4.53ms, mfu 22.14%
iter 960: loss 0.9183, time 4.38ms, mfu 22.29%
iter 970: loss 0.9121, time 4.35ms, mfu 22.45%
iter 980: loss 0.9154, time 4.72ms, mfu 22.40%
iter 990: loss 0.9030, time 4.69ms, mfu 22.37%
step 1000: train loss 0.9195, val loss 0.9203
saving checkpoint to out-experiment2_width-n_embd_192
iter 1000: loss 0.9347, time 1437.58ms, mfu 20.14%
iter 1010: loss 0.9088, time 4.72ms, mfu 20.32%
iter 1020: loss 0.9429, time 4.38ms, mfu 20.66%
iter 1030: loss 0.9013, time 4.33ms, mfu 20.99%
iter 1040: loss 0.9158, time 4.61ms, mfu 21.14%
iter 1050: loss 0.9283, time 4.34ms, mfu 21.41%
iter 1060: loss 0.8879, time 4.58ms, mfu 21.53%
iter 1070: loss 0.8999, time 4.36ms, mfu 21.75%
iter 1080: loss 0.8682, time 4.72ms, mfu 21.77%
iter 1090: loss 0.9003, time 4.63ms, mfu 21.83%
iter 1100: loss 0.9148, time 4.59ms, mfu 21.91%
iter 1110: loss 0.9037, time 4.69ms, mfu 21.93%
iter 1120: loss 0.9083, time 4.80ms, mfu 21.89%
iter 1130: loss 0.8853, time 4.58ms, mfu 21.97%
iter 1140: loss 0.8678, time 4.68ms, mfu 21.99%
iter 1150: loss 0.8872, time 4.45ms, mfu 22.12%
iter 1160: loss 0.8516, time 4.43ms, mfu 22.25%
iter 1170: loss 0.8934, time 4.54ms, mfu 22.31%
iter 1180: loss 0.8461, time 4.37ms, mfu 22.45%
iter 1190: loss 0.8481, time 4.32ms, mfu 22.61%
iter 1200: loss 0.8952, time 4.50ms, mfu 22.65%
iter 1210: loss 0.9148, time 4.32ms, mfu 22.78%
iter 1220: loss 0.8324, time 4.71ms, mfu 22.71%
iter 1230: loss 0.8687, time 4.61ms, mfu 22.69%
iter 1240: loss 0.8516, time 4.68ms, mfu 22.63%
step 1250: train loss 0.8535, val loss 0.8541
saving checkpoint to out-experiment2_width-n_embd_192
iter 1250: loss 0.8455, time 1410.64ms, mfu 20.38%
iter 1260: loss 0.8381, time 4.72ms, mfu 20.53%
iter 1270: loss 0.8978, time 4.64ms, mfu 20.72%
iter 1280: loss 0.8487, time 4.57ms, mfu 20.91%
iter 1290: loss 0.8471, time 4.81ms, mfu 20.98%
iter 1300: loss 0.8372, time 4.29ms, mfu 21.30%
iter 1310: loss 0.8434, time 4.62ms, mfu 21.41%
iter 1320: loss 0.8327, time 4.34ms, mfu 21.66%
iter 1330: loss 0.8007, time 4.63ms, mfu 21.73%
iter 1340: loss 0.8377, time 4.66ms, mfu 21.78%
iter 1350: loss 0.8516, time 4.67ms, mfu 21.83%
iter 1360: loss 0.8643, time 4.32ms, mfu 22.04%
iter 1370: loss 0.8168, time 4.32ms, mfu 22.24%
iter 1380: loss 0.8478, time 4.59ms, mfu 22.27%
iter 1390: loss 0.8318, time 4.41ms, mfu 22.40%
iter 1400: loss 0.7740, time 4.35ms, mfu 22.54%
iter 1410: loss 0.8402, time 4.56ms, mfu 22.56%
iter 1420: loss 0.7935, time 4.70ms, mfu 22.51%
iter 1430: loss 0.8345, time 4.61ms, mfu 22.50%
iter 1440: loss 0.8191, time 4.61ms, mfu 22.50%
iter 1450: loss 0.8400, time 4.59ms, mfu 22.51%
iter 1460: loss 0.8299, time 4.71ms, mfu 22.46%
iter 1470: loss 0.8061, time 4.35ms, mfu 22.60%
iter 1480: loss 0.8260, time 4.56ms, mfu 22.61%
iter 1490: loss 0.8281, time 4.31ms, mfu 22.75%
step 1500: train loss 0.8125, val loss 0.8123
saving checkpoint to out-experiment2_width-n_embd_192
iter 1500: loss 0.7936, time 1428.21ms, mfu 20.48%
iter 1510: loss 0.7531, time 4.85ms, mfu 20.57%
iter 1520: loss 0.7983, time 4.48ms, mfu 20.83%
iter 1530: loss 0.7883, time 4.52ms, mfu 21.04%
iter 1540: loss 0.8251, time 4.58ms, mfu 21.20%
iter 1550: loss 0.7980, time 4.41ms, mfu 21.43%
iter 1560: loss 0.7980, time 4.44ms, mfu 21.62%
iter 1570: loss 0.8047, time 4.76ms, mfu 21.63%
iter 1580: loss 0.8074, time 4.52ms, mfu 21.76%
iter 1590: loss 0.8069, time 4.33ms, mfu 21.98%
iter 1600: loss 0.8412, time 4.32ms, mfu 22.18%
iter 1610: loss 0.7987, time 4.61ms, mfu 22.21%
iter 1620: loss 0.7901, time 4.34ms, mfu 22.38%
iter 1630: loss 0.7900, time 4.39ms, mfu 22.50%
iter 1640: loss 0.7873, time 4.73ms, mfu 22.45%
iter 1650: loss 0.7983, time 4.60ms, mfu 22.45%
iter 1660: loss 0.8208, time 4.72ms, mfu 22.40%
iter 1670: loss 0.7966, time 4.56ms, mfu 22.44%
iter 1680: loss 0.7811, time 4.34ms, mfu 22.58%
iter 1690: loss 0.7971, time 4.68ms, mfu 22.54%
iter 1700: loss 0.8132, time 4.34ms, mfu 22.67%
iter 1710: loss 0.8129, time 4.36ms, mfu 22.78%
iter 1720: loss 0.7868, time 4.73ms, mfu 22.70%
iter 1730: loss 0.7748, time 4.34ms, mfu 22.81%
iter 1740: loss 0.8042, time 4.52ms, mfu 22.83%
step 1750: train loss 0.7755, val loss 0.7770
saving checkpoint to out-experiment2_width-n_embd_192
iter 1750: loss 0.7867, time 1449.90ms, mfu 20.55%
iter 1760: loss 0.8037, time 4.38ms, mfu 20.86%
iter 1770: loss 0.7676, time 4.83ms, mfu 20.93%
iter 1780: loss 0.7910, time 4.67ms, mfu 21.06%
iter 1790: loss 0.7973, time 8.53ms, mfu 20.17%
iter 1800: loss 0.7733, time 4.68ms, mfu 20.36%
iter 1810: loss 0.7844, time 4.74ms, mfu 20.51%
iter 1820: loss 0.7509, time 4.58ms, mfu 20.73%
iter 1830: loss 0.7892, time 4.78ms, mfu 20.82%
iter 1840: loss 0.7205, time 4.57ms, mfu 21.01%
iter 1850: loss 0.7472, time 4.52ms, mfu 21.20%
iter 1860: loss 0.7598, time 4.57ms, mfu 21.35%
iter 1870: loss 0.7628, time 4.42ms, mfu 21.56%
iter 1880: loss 0.7930, time 4.82ms, mfu 21.56%
iter 1890: loss 0.7372, time 4.41ms, mfu 21.75%
iter 1900: loss 0.7550, time 4.66ms, mfu 21.80%
iter 1910: loss 0.7859, time 4.58ms, mfu 21.88%
iter 1920: loss 0.7695, time 4.51ms, mfu 22.00%
iter 1930: loss 0.7392, time 4.29ms, mfu 22.21%
iter 1940: loss 0.7717, time 4.59ms, mfu 22.25%
iter 1950: loss 0.7652, time 4.70ms, mfu 22.23%
iter 1960: loss 0.7720, time 4.86ms, mfu 22.14%
iter 1970: loss 0.7587, time 4.62ms, mfu 22.17%
iter 1980: loss 0.7569, time 4.51ms, mfu 22.26%
iter 1990: loss 0.7504, time 4.54ms, mfu 22.31%
step 2000: train loss 0.7522, val loss 0.7498
saving checkpoint to out-experiment2_width-n_embd_192
iter 2000: loss 0.7388, time 1449.47ms, mfu 20.09%
iter 2010: loss 0.7256, time 4.63ms, mfu 20.32%
iter 2020: loss 0.7743, time 4.72ms, mfu 20.48%
iter 2030: loss 0.7679, time 4.65ms, mfu 20.66%
iter 2040: loss 0.7220, time 4.38ms, mfu 20.97%
iter 2050: loss 0.7741, time 4.61ms, mfu 21.12%
iter 2060: loss 0.7297, time 4.32ms, mfu 21.41%
iter 2070: loss 0.7655, time 4.43ms, mfu 21.61%
iter 2080: loss 0.7441, time 4.57ms, mfu 21.71%
iter 2090: loss 0.7948, time 4.83ms, mfu 21.69%
iter 2100: loss 0.7512, time 4.54ms, mfu 21.80%
iter 2110: loss 0.7715, time 4.34ms, mfu 22.00%
iter 2120: loss 0.7311, time 4.36ms, mfu 22.18%
iter 2130: loss 0.7294, time 4.66ms, mfu 22.19%
iter 2140: loss 0.7764, time 4.59ms, mfu 22.23%
iter 2150: loss 0.7451, time 4.60ms, mfu 22.26%
iter 2160: loss 0.7155, time 4.59ms, mfu 22.29%
iter 2170: loss 0.7256, time 4.33ms, mfu 22.46%
iter 2180: loss 0.7111, time 4.34ms, mfu 22.60%
iter 2190: loss 0.7635, time 4.36ms, mfu 22.72%
iter 2200: loss 0.7484, time 4.72ms, mfu 22.65%
iter 2210: loss 0.7296, time 4.56ms, mfu 22.65%
iter 2220: loss 0.7370, time 4.31ms, mfu 22.79%
iter 2230: loss 0.7385, time 4.71ms, mfu 22.71%
iter 2240: loss 0.7295, time 4.47ms, mfu 22.76%
step 2250: train loss 0.7326, val loss 0.7293
saving checkpoint to out-experiment2_width-n_embd_192
iter 2250: loss 0.7676, time 1433.66ms, mfu 20.49%
iter 2260: loss 0.7270, time 4.71ms, mfu 20.65%
iter 2270: loss 0.7007, time 4.65ms, mfu 20.81%
iter 2280: loss 0.7247, time 4.37ms, mfu 21.10%
iter 2290: loss 0.7481, time 4.36ms, mfu 21.37%
iter 2300: loss 0.7383, time 4.37ms, mfu 21.61%
iter 2310: loss 0.7374, time 4.60ms, mfu 21.70%
iter 2320: loss 0.7111, time 4.62ms, mfu 21.77%
iter 2330: loss 0.7334, time 4.60ms, mfu 21.85%
iter 2340: loss 0.7189, time 4.69ms, mfu 21.88%
iter 2350: loss 0.7197, time 4.63ms, mfu 21.93%
iter 2360: loss 0.7814, time 4.66ms, mfu 21.96%
iter 2370: loss 0.6893, time 4.41ms, mfu 22.11%
iter 2380: loss 0.7213, time 4.34ms, mfu 22.29%
iter 2390: loss 0.7297, time 4.44ms, mfu 22.40%
iter 2400: loss 0.6900, time 4.32ms, mfu 22.56%
iter 2410: loss 0.7072, time 4.59ms, mfu 22.56%
iter 2420: loss 0.7256, time 4.54ms, mfu 22.59%
iter 2430: loss 0.7172, time 4.66ms, mfu 22.55%
iter 2440: loss 0.7062, time 4.33ms, mfu 22.69%
iter 2450: loss 0.6975, time 4.35ms, mfu 22.81%
iter 2460: loss 0.7091, time 4.61ms, mfu 22.77%
iter 2470: loss 0.7128, time 4.67ms, mfu 22.71%
iter 2480: loss 0.7532, time 4.41ms, mfu 22.79%
iter 2490: loss 0.7249, time 4.62ms, mfu 22.76%
step 2500: train loss 0.7134, val loss 0.7148
saving checkpoint to out-experiment2_width-n_embd_192
iter 2500: loss 0.7351, time 1429.47ms, mfu 20.49%
iter 2510: loss 0.7302, time 4.34ms, mfu 20.83%
iter 2520: loss 0.6896, time 4.29ms, mfu 21.16%
iter 2530: loss 0.6935, time 4.36ms, mfu 21.42%
iter 2540: loss 0.7255, time 4.56ms, mfu 21.55%
iter 2550: loss 0.6925, time 4.62ms, mfu 21.64%
iter 2560: loss 0.7223, time 4.57ms, mfu 21.75%
iter 2570: loss 0.6980, time 4.29ms, mfu 21.99%
iter 2580: loss 0.7330, time 4.57ms, mfu 22.06%
iter 2590: loss 0.7049, time 4.30ms, mfu 22.26%
iter 2600: loss 0.6919, time 4.29ms, mfu 22.46%
iter 2610: loss 0.7395, time 4.60ms, mfu 22.46%
iter 2620: loss 0.7052, time 4.30ms, mfu 22.63%
iter 2630: loss 0.7098, time 6.60ms, mfu 21.94%
iter 2640: loss 0.7111, time 4.40ms, mfu 22.10%
iter 2650: loss 0.6871, time 4.63ms, mfu 22.13%
iter 2660: loss 0.6615, time 4.65ms, mfu 22.15%
iter 2670: loss 0.7181, time 4.35ms, mfu 22.31%
iter 2680: loss 0.6947, time 4.53ms, mfu 22.37%
iter 2690: loss 0.7314, time 4.35ms, mfu 22.52%
iter 2700: loss 0.7131, time 4.72ms, mfu 22.47%
iter 2710: loss 0.7277, time 4.34ms, mfu 22.61%
iter 2720: loss 0.7076, time 4.43ms, mfu 22.68%
iter 2730: loss 0.6972, time 4.36ms, mfu 22.79%
iter 2740: loss 0.7047, time 4.82ms, mfu 22.66%
step 2750: train loss 0.6993, val loss 0.7001
saving checkpoint to out-experiment2_width-n_embd_192
iter 2750: loss 0.6990, time 1445.76ms, mfu 20.40%
iter 2760: loss 0.7047, time 4.34ms, mfu 20.75%
iter 2770: loss 0.7034, time 4.57ms, mfu 20.95%
iter 2780: loss 0.7039, time 4.54ms, mfu 21.13%
iter 2790: loss 0.7186, time 4.60ms, mfu 21.27%
iter 2800: loss 0.6893, time 4.64ms, mfu 21.38%
iter 2810: loss 0.7160, time 4.52ms, mfu 21.54%
iter 2820: loss 0.6976, time 4.55ms, mfu 21.66%
iter 2830: loss 0.6838, time 4.61ms, mfu 21.74%
iter 2840: loss 0.7269, time 4.43ms, mfu 21.91%
iter 2850: loss 0.6671, time 4.68ms, mfu 21.94%
iter 2860: loss 0.7098, time 4.29ms, mfu 22.16%
iter 2870: loss 0.6755, time 4.60ms, mfu 22.20%
iter 2880: loss 0.6800, time 4.54ms, mfu 22.26%
iter 2890: loss 0.6765, time 4.60ms, mfu 22.29%
iter 2900: loss 0.7008, time 4.63ms, mfu 22.30%
iter 2910: loss 0.6573, time 4.66ms, mfu 22.29%
iter 2920: loss 0.7128, time 4.55ms, mfu 22.34%
iter 2930: loss 0.6735, time 4.45ms, mfu 22.44%
iter 2940: loss 0.7181, time 4.30ms, mfu 22.61%
iter 2950: loss 0.6809, time 4.65ms, mfu 22.58%
iter 2960: loss 0.6747, time 4.55ms, mfu 22.60%
iter 2970: loss 0.6652, time 4.57ms, mfu 22.61%
iter 2980: loss 0.6708, time 4.58ms, mfu 22.61%
iter 2990: loss 0.6814, time 4.38ms, mfu 22.72%
step 3000: train loss 0.6859, val loss 0.6860
saving checkpoint to out-experiment2_width-n_embd_192
iter 3000: loss 0.6783, time 1442.40ms, mfu 20.45%
iter 3010: loss 0.6576, time 4.53ms, mfu 20.69%
iter 3020: loss 0.7040, time 4.55ms, mfu 20.90%
iter 3030: loss 0.6649, time 4.66ms, mfu 21.04%
iter 3040: loss 0.6707, time 4.43ms, mfu 21.27%
iter 3050: loss 0.6713, time 4.24ms, mfu 21.59%
iter 3060: loss 0.7188, time 4.66ms, mfu 21.66%
iter 3070: loss 0.7146, time 4.57ms, mfu 21.76%
iter 3080: loss 0.6818, time 4.32ms, mfu 21.98%
iter 3090: loss 0.6748, time 4.29ms, mfu 22.20%
iter 3100: loss 0.6715, time 4.56ms, mfu 22.26%
iter 3110: loss 0.6708, time 4.23ms, mfu 22.48%
iter 3120: loss 0.6774, time 4.59ms, mfu 22.49%
iter 3130: loss 0.6689, time 4.35ms, mfu 22.62%
iter 3140: loss 0.6815, time 4.50ms, mfu 22.67%
iter 3150: loss 0.6946, time 4.77ms, mfu 22.57%
iter 3160: loss 0.6752, time 4.57ms, mfu 22.58%
iter 3170: loss 0.6927, time 4.59ms, mfu 22.58%
iter 3180: loss 0.6735, time 4.59ms, mfu 22.59%
iter 3190: loss 0.6350, time 4.59ms, mfu 22.59%
iter 3200: loss 0.6745, time 4.54ms, mfu 22.61%
iter 3210: loss 0.6760, time 4.60ms, mfu 22.60%
iter 3220: loss 0.6883, time 4.64ms, mfu 22.57%
iter 3230: loss 0.6846, time 4.59ms, mfu 22.58%
iter 3240: loss 0.6611, time 4.32ms, mfu 22.72%
step 3250: train loss 0.6753, val loss 0.6744
saving checkpoint to out-experiment2_width-n_embd_192
iter 3250: loss 0.6820, time 1447.95ms, mfu 20.45%
iter 3260: loss 0.6497, time 4.33ms, mfu 20.80%
iter 3270: loss 0.6697, time 4.91ms, mfu 20.83%
iter 3280: loss 0.6848, time 4.65ms, mfu 20.98%
iter 3290: loss 0.7011, time 4.30ms, mfu 21.29%
iter 3300: loss 0.6663, time 4.32ms, mfu 21.56%
iter 3310: loss 0.6596, time 4.29ms, mfu 21.82%
iter 3320: loss 0.6647, time 4.53ms, mfu 21.93%
iter 3330: loss 0.6774, time 4.76ms, mfu 21.91%
iter 3340: loss 0.6350, time 4.66ms, mfu 21.95%
iter 3350: loss 0.6765, time 4.48ms, mfu 22.07%
iter 3360: loss 0.6317, time 4.70ms, mfu 22.07%
iter 3370: loss 0.6776, time 4.42ms, mfu 22.20%
iter 3380: loss 0.6924, time 4.53ms, mfu 22.27%
iter 3390: loss 0.6790, time 4.60ms, mfu 22.30%
iter 3400: loss 0.6517, time 4.67ms, mfu 22.29%
iter 3410: loss 0.7077, time 4.58ms, mfu 22.32%
iter 3420: loss 0.6750, time 4.59ms, mfu 22.35%
iter 3430: loss 0.6737, time 4.54ms, mfu 22.40%
iter 3440: loss 0.6665, time 4.60ms, mfu 22.41%
iter 3450: loss 0.6952, time 4.53ms, mfu 22.46%
iter 3460: loss 0.6960, time 4.31ms, mfu 22.62%
iter 3470: loss 0.6876, time 4.55ms, mfu 22.64%
iter 3480: loss 0.6840, time 4.74ms, mfu 22.56%
iter 3490: loss 0.6252, time 4.58ms, mfu 22.57%
step 3500: train loss 0.6655, val loss 0.6653
saving checkpoint to out-experiment2_width-n_embd_192
iter 3500: loss 0.6798, time 1452.70ms, mfu 20.32%
iter 3510: loss 0.6586, time 4.60ms, mfu 20.54%
iter 3520: loss 0.6705, time 4.73ms, mfu 20.67%
iter 3530: loss 0.6773, time 4.58ms, mfu 20.87%
iter 3540: loss 0.6746, time 4.67ms, mfu 21.01%
iter 3550: loss 0.6792, time 4.61ms, mfu 21.15%
iter 3560: loss 0.6642, time 4.29ms, mfu 21.46%
iter 3570: loss 0.6595, time 4.60ms, mfu 21.56%
iter 3580: loss 0.6249, time 4.62ms, mfu 21.65%
iter 3590: loss 0.6793, time 4.57ms, mfu 21.75%
iter 3600: loss 0.6283, time 4.66ms, mfu 21.80%
iter 3610: loss 0.7133, time 4.29ms, mfu 22.04%
iter 3620: loss 0.6675, time 4.36ms, mfu 22.21%
iter 3630: loss 0.6392, time 4.55ms, mfu 22.26%
iter 3640: loss 0.6344, time 4.51ms, mfu 22.34%
iter 3650: loss 0.6619, time 4.72ms, mfu 22.30%
iter 3660: loss 0.6650, time 4.29ms, mfu 22.48%
iter 3670: loss 0.6495, time 4.57ms, mfu 22.51%
iter 3680: loss 0.6478, time 4.60ms, mfu 22.51%
iter 3690: loss 0.6885, time 6.74ms, mfu 21.80%
iter 3700: loss 0.6516, time 4.71ms, mfu 21.81%
iter 3710: loss 0.6479, time 4.53ms, mfu 21.92%
iter 3720: loss 0.6485, time 4.64ms, mfu 21.96%
iter 3730: loss 0.6404, time 4.36ms, mfu 22.14%
iter 3740: loss 0.6727, time 4.30ms, mfu 22.34%
step 3750: train loss 0.6578, val loss 0.6577
saving checkpoint to out-experiment2_width-n_embd_192
iter 3750: loss 0.6782, time 1447.85ms, mfu 20.11%
iter 3760: loss 0.6322, time 4.48ms, mfu 20.42%
iter 3770: loss 0.6650, time 4.36ms, mfu 20.75%
iter 3780: loss 0.6288, time 4.61ms, mfu 20.93%
iter 3790: loss 0.6763, time 4.53ms, mfu 21.12%
iter 3800: loss 0.6536, time 4.58ms, mfu 21.27%
iter 3810: loss 0.6142, time 4.60ms, mfu 21.40%
iter 3820: loss 0.6306, time 4.68ms, mfu 21.48%
iter 3830: loss 0.6571, time 4.61ms, mfu 21.58%
iter 3840: loss 0.6355, time 4.57ms, mfu 21.69%
iter 3850: loss 0.6763, time 4.55ms, mfu 21.80%
iter 3860: loss 0.6668, time 4.56ms, mfu 21.89%
iter 3870: loss 0.6491, time 4.37ms, mfu 22.07%
iter 3880: loss 0.6347, time 4.31ms, mfu 22.27%
iter 3890: loss 0.6336, time 4.28ms, mfu 22.46%
iter 3900: loss 0.6774, time 4.39ms, mfu 22.58%
iter 3910: loss 0.6577, time 4.63ms, mfu 22.56%
iter 3920: loss 0.6596, time 4.68ms, mfu 22.52%
iter 3930: loss 0.6081, time 4.62ms, mfu 22.51%
iter 3940: loss 0.6744, time 4.51ms, mfu 22.56%
iter 3950: loss 0.6478, time 4.33ms, mfu 22.70%
iter 3960: loss 0.6923, time 4.55ms, mfu 22.71%
iter 3970: loss 0.6762, time 4.37ms, mfu 22.81%
iter 3980: loss 0.6340, time 4.50ms, mfu 22.83%
iter 3990: loss 0.6474, time 4.41ms, mfu 22.90%
step 4000: train loss 0.6498, val loss 0.6473
saving checkpoint to out-experiment2_width-n_embd_192
iter 4000: loss 0.6228, time 1438.49ms, mfu 20.62%
iter 4010: loss 0.6845, time 4.33ms, mfu 20.95%
iter 4020: loss 0.6544, time 4.62ms, mfu 21.10%
iter 4030: loss 0.6297, time 4.67ms, mfu 21.21%
iter 4040: loss 0.6442, time 4.28ms, mfu 21.51%
iter 4050: loss 0.6801, time 4.52ms, mfu 21.65%
iter 4060: loss 0.6407, time 4.50ms, mfu 21.79%
iter 4070: loss 0.6562, time 4.44ms, mfu 21.94%
iter 4080: loss 0.6280, time 4.67ms, mfu 21.97%
iter 4090: loss 0.6385, time 4.36ms, mfu 22.15%
iter 4100: loss 0.6476, time 4.71ms, mfu 22.13%
iter 4110: loss 0.6240, time 4.50ms, mfu 22.22%
iter 4120: loss 0.6411, time 4.67ms, mfu 22.22%
iter 4130: loss 0.6378, time 4.73ms, mfu 22.19%
iter 4140: loss 0.6613, time 4.57ms, mfu 22.24%
iter 4150: loss 0.6461, time 4.36ms, mfu 22.39%
iter 4160: loss 0.6460, time 4.27ms, mfu 22.58%
iter 4170: loss 0.6876, time 4.74ms, mfu 22.51%
iter 4180: loss 0.6759, time 4.73ms, mfu 22.45%
iter 4190: loss 0.6356, time 4.53ms, mfu 22.50%
iter 4200: loss 0.6260, time 4.28ms, mfu 22.67%
iter 4210: loss 0.6369, time 4.41ms, mfu 22.75%
iter 4220: loss 0.6302, time 4.43ms, mfu 22.82%
iter 4230: loss 0.6607, time 4.75ms, mfu 22.72%
iter 4240: loss 0.6518, time 4.74ms, mfu 22.63%
step 4250: train loss 0.6442, val loss 0.6410
saving checkpoint to out-experiment2_width-n_embd_192
iter 4250: loss 0.6417, time 1439.73ms, mfu 20.38%
iter 4260: loss 0.6808, time 4.86ms, mfu 20.47%
iter 4270: loss 0.6459, time 4.82ms, mfu 20.58%
iter 4280: loss 0.6504, time 4.35ms, mfu 20.90%
iter 4290: loss 0.6309, time 4.66ms, mfu 21.04%
iter 4300: loss 0.6323, time 4.67ms, mfu 21.15%
iter 4310: loss 0.6478, time 4.39ms, mfu 21.40%
iter 4320: loss 0.6320, time 4.37ms, mfu 21.64%
iter 4330: loss 0.6860, time 4.35ms, mfu 21.85%
iter 4340: loss 0.6210, time 4.44ms, mfu 22.00%
iter 4350: loss 0.6345, time 4.74ms, mfu 21.99%
iter 4360: loss 0.6185, time 4.75ms, mfu 21.97%
iter 4370: loss 0.6303, time 4.63ms, mfu 22.01%
iter 4380: loss 0.6463, time 4.81ms, mfu 21.96%
iter 4390: loss 0.6457, time 4.58ms, mfu 22.03%
iter 4400: loss 0.6588, time 4.54ms, mfu 22.11%
iter 4410: loss 0.6047, time 4.59ms, mfu 22.16%
iter 4420: loss 0.6306, time 4.38ms, mfu 22.31%
iter 4430: loss 0.6283, time 4.56ms, mfu 22.36%
iter 4440: loss 0.6143, time 4.65ms, mfu 22.35%
iter 4450: loss 0.6552, time 4.39ms, mfu 22.48%
iter 4460: loss 0.6471, time 4.26ms, mfu 22.66%
iter 4470: loss 0.6321, time 4.99ms, mfu 22.47%
iter 4480: loss 0.6314, time 4.47ms, mfu 22.54%
iter 4490: loss 0.6026, time 4.63ms, mfu 22.53%
step 4500: train loss 0.6372, val loss 0.6358
saving checkpoint to out-experiment2_width-n_embd_192
iter 4500: loss 0.6131, time 1457.24ms, mfu 20.29%
iter 4510: loss 0.6186, time 4.73ms, mfu 20.45%
iter 4520: loss 0.6770, time 4.39ms, mfu 20.76%
iter 4530: loss 0.6507, time 4.56ms, mfu 20.96%
iter 4540: loss 0.5954, time 4.45ms, mfu 21.19%
iter 4550: loss 0.6336, time 4.84ms, mfu 21.22%
iter 4560: loss 0.6304, time 4.78ms, mfu 21.26%
iter 4570: loss 0.6542, time 4.58ms, mfu 21.40%
iter 4580: loss 0.6416, time 4.61ms, mfu 21.51%
iter 4590: loss 0.6276, time 4.54ms, mfu 21.64%
iter 4600: loss 0.5983, time 4.74ms, mfu 21.67%
iter 4610: loss 0.6442, time 4.64ms, mfu 21.73%
iter 4620: loss 0.6356, time 4.60ms, mfu 21.81%
iter 4630: loss 0.6153, time 4.28ms, mfu 22.05%
iter 4640: loss 0.6357, time 4.58ms, mfu 22.11%
iter 4650: loss 0.6233, time 4.49ms, mfu 22.21%
iter 4660: loss 0.6251, time 4.66ms, mfu 22.21%
iter 4670: loss 0.6217, time 4.55ms, mfu 22.27%
iter 4680: loss 0.6273, time 4.67ms, mfu 22.27%
iter 4690: loss 0.6157, time 4.57ms, mfu 22.31%
iter 4700: loss 0.6287, time 4.58ms, mfu 22.34%
iter 4710: loss 0.6337, time 4.68ms, mfu 22.33%
iter 4720: loss 0.6024, time 4.36ms, mfu 22.47%
iter 4730: loss 0.6627, time 4.65ms, mfu 22.45%
iter 4740: loss 0.6478, time 4.38ms, mfu 22.57%
step 4750: train loss 0.6327, val loss 0.6330
saving checkpoint to out-experiment2_width-n_embd_192
iter 4750: loss 0.6594, time 1457.48ms, mfu 20.32%
iter 4760: loss 0.6581, time 4.59ms, mfu 20.55%
iter 4770: loss 0.6541, time 4.61ms, mfu 20.74%
iter 4780: loss 0.6208, time 4.59ms, mfu 20.93%
iter 4790: loss 0.6426, time 4.70ms, mfu 21.04%
iter 4800: loss 0.6191, time 4.82ms, mfu 21.09%
iter 4810: loss 0.6266, time 4.72ms, mfu 21.18%
iter 4820: loss 0.6285, time 4.48ms, mfu 21.37%
iter 4830: loss 0.6175, time 4.66ms, mfu 21.46%
iter 4840: loss 0.6268, time 4.30ms, mfu 21.72%
iter 4850: loss 0.6142, time 4.56ms, mfu 21.83%
iter 4860: loss 0.6246, time 4.32ms, mfu 22.04%
iter 4870: loss 0.6268, time 4.76ms, mfu 22.02%
iter 4880: loss 0.6542, time 4.36ms, mfu 22.19%
iter 4890: loss 0.5746, time 4.30ms, mfu 22.39%
iter 4900: loss 0.6484, time 4.30ms, mfu 22.56%
iter 4910: loss 0.6025, time 4.55ms, mfu 22.58%
iter 4920: loss 0.6361, time 4.56ms, mfu 22.59%
iter 4930: loss 0.5982, time 4.35ms, mfu 22.72%
iter 4940: loss 0.5919, time 4.29ms, mfu 22.86%
iter 4950: loss 0.6517, time 4.60ms, mfu 22.83%
iter 4960: loss 0.6837, time 4.31ms, mfu 22.95%
iter 4970: loss 0.6386, time 4.61ms, mfu 22.90%
iter 4980: loss 0.6161, time 4.70ms, mfu 22.82%
iter 4990: loss 0.6344, time 4.48ms, mfu 22.85%
step 5000: train loss 0.6296, val loss 0.6312
saving checkpoint to out-experiment2_width-n_embd_192
iter 5000: loss 0.6154, time 1463.72ms, mfu 20.57%


STDERR:
/data/lst141/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
