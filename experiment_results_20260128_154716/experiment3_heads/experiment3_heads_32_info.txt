Experiment: Attention Head Sweep (n_head)
Parameter varied: n_head = 32
Output directory: out-experiment3_heads-n_head_32
Timestamp: 2026-01-28 16:06:19

Configuration:
  always_save_checkpoint: False
  batch_size: 64
  beta2: 0.99
  block_size: 256
  dataset: tinystories
  device: cuda:1
  dropout: 0.0
  eval_interval: 250
  eval_iters: 200
  gradient_accumulation_steps: 1
  learning_rate: 0.001
  log_interval: 10
  lr_decay_iters: 5000
  max_iters: 5000
  min_lr: 0.0001
  n_embd: 256
  n_head: 32
  n_layer: 6
  out_dir: out-experiment3_heads-n_head_32
  wandb_log: False
  wandb_project: tinystories
  wandb_run_name: experiment3_heads_n_head_32
  warmup_iters: 100
